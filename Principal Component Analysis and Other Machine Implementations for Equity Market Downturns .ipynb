{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we predict recessions or equity market downturns given publicly available macroeconomic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Inspiration \n",
    "# https://medium.com/@romanm111987/predicting-stock-market-crashes-with-statistical-machine-learning-techniques-and-neural-networks-b756d9b48497\n",
    "# https://github.com/roman807/Predicting-Stock-Market-Crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First batch of data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "SP500 = pd.read_csv('Data/SP500.csv')\n",
    "T10T3 = pd.read_csv('Data/103.csv')\n",
    "uRate = pd.read_csv('Data/Unrate.csv')\n",
    "nfci = pd.read_csv('Data/nfci.csv')\n",
    "GDP = pd.read_csv('Data/GDP.csv')\n",
    "\n",
    "# Second batch of data\n",
    "USDindex = pd.read_csv('Data/USDIndex.csv')\n",
    "ManufacturingConfidence = pd.read_csv('Data/ManufacturingConfidence.csv')\n",
    "HousePriceIndex = pd.read_csv('Data/HousePriceIndex.csv')\n",
    "ConsumerSentiment = pd.read_csv('Data/ConsumerSentiment.csv')\n",
    "PeopleOutputPerHour = pd.read_csv('Data/PeopleOutputPerHour.csv')\n",
    "GS10 = pd.read_csv('Data/GS10.csv')\n",
    "FEDFUNDS = pd.read_csv('Data/FEDFUNDS.csv')\n",
    "USNIM = pd.read_csv('Data/USNIM.csv')\n",
    "govtToGDP = pd.read_csv('Data/govtToGDP.csv')\n",
    "CorporateProfits = pd.read_csv('Data/CorporateProfits.csv')\n",
    "VIX = pd.read_csv('Data/VIX.csv')\n",
    "\n",
    "# Annoying to integrate all these right now\n",
    "#highYield = pd.read_csv('Data/highYield.csv')\n",
    "#highYield = highYield.iloc[1:]\n",
    "#BBB = pd.read_csv('Data/BBB.csv')\n",
    "#BBB = BBB.iloc[1:]\n",
    "#IG = pd.read_csv('Data/IG.csv')\n",
    "#IG = IG.iloc[1:]\n",
    "\n",
    "# Add these\n",
    "# https://www.quandl.com/data/MULTPL/SHILLER_PE_RATIO_MONTH-Shiller-PE-Ratio-by-Month\n",
    "# https://fred.stlouisfed.org/series/USREC\n",
    "# https://fred.stlouisfed.org/series/M1\n",
    "# https://fred.stlouisfed.org/series/M2\n",
    "# https://fred.stlouisfed.org/series/MABMM301USM189S\n",
    "# https://research.stlouisfed.org/\n",
    "# https://fred.stlouisfed.org/series/CSUSHPISA\n",
    "# https://fred.stlouisfed.org/series/USSLIND\n",
    "# Add one year and three year performance to S&P \n",
    "# https://fred.stlouisfed.org/series/TEDRATE\n",
    "# https://fred.stlouisfed.org/series/CUSR0000SAC\n",
    "#  https://fred.stlouisfed.org/series/DEXJPUS\n",
    "# https://fred.stlouisfed.org/series/PERMIT\n",
    "# https://fred.stlouisfed.org/series/T10YFFM\n",
    "# https://www.quandl.com/data/FRED/NAPMPI-ISM-Manufacturing-Production-Index\n",
    "# https://fred.stlouisfed.org/series/PAYEMS\n",
    "# https://www.quandl.com/data/FRED/NAPM-ISM-Manufacturing-PMI-Composite-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourData = [SP500, T10T3, uRate, nfci, GDP, USDindex,\n",
    "          ManufacturingConfidence, HousePriceIndex, ConsumerSentiment,\n",
    "          PeopleOutputPerHour, GS10, FEDFUNDS, USNIM, govtToGDP, CorporateProfits, VIX]#, highYield, BBB, IG]\n",
    "dataName = ['SP500', 'T10T3', 'uRate', 'nfci', 'GDP', 'USDIndex',\n",
    "           'ManufacturingConfidence', 'HousePriceIndex', 'ConsumerSentiment',\n",
    "          'PeopleOutputPerHour', 'GS10', 'FEDFUNDS', 'USNIM', 'govtToGDP', 'CorporateProfits', 'VIX']#, 'highYield', 'BBB', 'IG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP data reporting is 3 months\n",
      "1990 is the last year in the data, and it is from VIX\n"
     ]
    }
   ],
   "source": [
    "maxData = 0\n",
    "maxDataType = 'xyz'\n",
    "maxYear = 0\n",
    "maxYearType = 'xyz'\n",
    "\n",
    "for i in range(0, len(ourData)):\n",
    "    start = '/'\n",
    "    end = '/'\n",
    "    \n",
    "    date1 = ourData[i]['Date'][0]\n",
    "    \n",
    "    thisYear = int(date1[-4:])\n",
    "    #print(thisYear, dataName[i])\n",
    "    \n",
    "    if thisYear > maxYear:\n",
    "        maxYear = thisYear\n",
    "        maxYearType = dataName[i]\n",
    "    \n",
    "    date2 = ourData[i]['Date'][1]\n",
    "    #print(date2)\n",
    "    #print('Month', date2.split('/')[0])\n",
    "    #print((date2.split(start))[1].split(end)[0])\n",
    "    #print(dataName[i], \":\", int(date2.split('/')[0]) - int(date1.split('/')[0]))\n",
    "    if (int(date2.split('/')[0]) - int(date1.split('/')[0])) > maxData:\n",
    "        maxData = int(date2.split('/')[0]) - int(date1.split('/')[0])\n",
    "        maxDataType = dataName[i]\n",
    "print(maxDataType, \"data reporting is\", maxData, \"months\")\n",
    "print(maxYear, \"is the last year in the data, and it is from\", maxYearType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year column for all data\n",
    "\n",
    "for i in range(0, len(ourData)):\n",
    "    # Why can't we get year to match up to the column length\n",
    "    yearList = [0] * len(ourData[i])\n",
    "    #print(len(yearList))\n",
    "    for j in range(0, len(yearList)):        \n",
    "        dateValue = ourData[i]['Date'][j]        \n",
    "        thisDate = int(dateValue[-4:])\n",
    "        yearList[j] = thisDate\n",
    "    ourData[i]['Year'] = yearList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on the max year\n",
    "\n",
    "for i in range(0, len(ourData)):\n",
    "    ourData[i]['Year'].astype(float)\n",
    "    ourData[i]['Year'] = ourData[i][ourData[i]['Year'] >= maxYear]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls \n",
    "for i in range(0, len(ourData)):\n",
    "    ourData[i] = ourData[i].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data outputs\n",
    "# for i in range(0, len(ourData)):\n",
    "    # print(ourData[i].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to filter out all data before 1982\n",
    "\n",
    "SP500 = ourData[0]\n",
    "T10T3 = ourData[1]\n",
    "uRate = ourData[2]\n",
    "nfci = ourData[3]\n",
    "GDP = ourData[4]\n",
    "USDindex = ourData[5]\n",
    "ManufacturingConfidence = ourData[6]\n",
    "HousePriceIndex = ourData[7]\n",
    "ConsumerSentiment = ourData[8]           \n",
    "PeopleOutputPerHour = ourData[9]\n",
    "GS10 = ourData[10]\n",
    "FEDFUNDS = ourData[11]\n",
    "USNIM = ourData[12]\n",
    "govtToGDP = ourData[13]\n",
    "CorporateProfits = ourData[14]\n",
    "VIX = ourData[15]\n",
    "#highYield = ourData[16]\n",
    "#BBB = ourData[17]\n",
    "#IG = ourData[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 GDP\n"
     ]
    }
   ],
   "source": [
    "ourData = [SP500, T10T3, uRate, nfci, GDP, USDindex,\n",
    "          ManufacturingConfidence, HousePriceIndex, ConsumerSentiment,\n",
    "          PeopleOutputPerHour, GS10, FEDFUNDS, USNIM, govtToGDP, CorporateProfits, VIX]#, highYield, BBB, IG]\n",
    "\n",
    "dataName = ['SP500', 'T10T3', 'uRate', 'nfci', 'GDP', 'USDIndex',\n",
    "           'ManufacturingConfidence', 'HousePriceIndex', 'ConsumerSentiment',\n",
    "          'PeopleOutputPerHour', 'GS10', 'FEDFUNDS', 'USNIM', 'govtToGDP', 'CorporateProfits', 'VIX']#, 'highYield', 'BBB', 'IG']\n",
    "\n",
    "smallestData = len(ourData[0])\n",
    "smallestDataName = dataName[0]\n",
    "\n",
    "for i in range(0, len(ourData)):\n",
    "    # print(len(ourData[i]), dataName[i])\n",
    "    if len(ourData[i]) < smallestData:\n",
    "        smallestData = len(ourData[i]) \n",
    "        smallestDataName = dataName[i]\n",
    "print(smallestData, smallestDataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dates lined up based on the smallest piece of data\n",
    "#dataGathering = [0] * len(GDP)\n",
    "w, h = 17, len(GDP); # This has to be based off the length of the shortest file\n",
    "results = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "newData = [SP500, T10T3, uRate, nfci, USDindex,\n",
    "          ManufacturingConfidence, HousePriceIndex, ConsumerSentiment,\n",
    "          PeopleOutputPerHour, GS10, FEDFUNDS, USNIM, govtToGDP, CorporateProfits, VIX] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "# Need to add a new incrementer to position every time a new variable is added to the test files.\n",
    "position1 = 0\n",
    "position2 = 0\n",
    "position3 = 0\n",
    "position4 = 0\n",
    "\n",
    "position5 = 0\n",
    "position6 = 0\n",
    "position7 = 0\n",
    "position8 = 0\n",
    "\n",
    "position9 = 0\n",
    "position10 = 0\n",
    "position11 = 0\n",
    "position12 = 0\n",
    "\n",
    "position13 = 0\n",
    "position14 = 0\n",
    "position15 = 0\n",
    "\n",
    "for i in range(0, len(GDP)): # This has to be based off the length of the shortest file\n",
    "    results[i][0] = GDP['Date'].iloc[i]\n",
    "    results[i][1] = round(GDP['GDP'].iloc[i], 2)    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[0]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[0]['Date'].iloc[i][-4:]:\n",
    "        results[i][2] = round(newData[0]['SP500'].iloc[i], 2)\n",
    "        # print(GDP['Date'].iloc[i])\n",
    "        # print(newData[0]['Date'].iloc[i])\n",
    "    else:\n",
    "        while position1 <= len(newData[0]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[0]['Date'].iloc[position1][:2]) and (GDP['Date'].iloc[i][-4:] == newData[0]['Date'].iloc[position1][-4:]):\n",
    "                results[i][2] = round(newData[0]['SP500'].iloc[position1], 2)\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[0]['Date'].iloc[position1])\n",
    "                break\n",
    "            else:\n",
    "                position1 = position1 + 1\n",
    "    if GDP['Date'].iloc[i][:2] == newData[1]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[1]['Date'].iloc[i][-4:]:\n",
    "        if newData[1]['T10Y3M'].iloc[position2] == 0:\n",
    "                results[i][3] = round(newData[1]['T10Y3M'].iloc[position2 + 1], 2)\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[1]['Date'].iloc[position2])\n",
    "        else:\n",
    "            results[i][3] = round(newData[1]['T10Y3M'].iloc[i], 2)\n",
    "    else:\n",
    "        while position2 <= len(newData[1]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[1]['Date'].iloc[position2][:2]) and (GDP['Date'].iloc[i][-4:] == newData[1]['Date'].iloc[position2][-4:]):\n",
    "                # Test if newData[1]['T10Y3M'].iloc[position2] == 0\n",
    "                # if so, take the next one from it\n",
    "                if newData[1]['T10Y3M'].iloc[position2] == 0:\n",
    "                    results[i][3] = round(newData[1]['T10Y3M'].iloc[position2 + 1], 2)\n",
    "                    # print(GDP['Date'].iloc[i])\n",
    "                    # print(newData[1]['Date'].iloc[position2])\n",
    "                else:\n",
    "                    results[i][3] = round(newData[1]['T10Y3M'].iloc[position2], 2)\n",
    "                    # print(GDP['Date'].iloc[i])\n",
    "                    # print(newData[1]['Date'].iloc[position2])\n",
    "                break\n",
    "            else:\n",
    "                position2 = position2 + 1\n",
    "    if GDP['Date'].iloc[i][:2] == newData[2]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[2]['Date'].iloc[i][-4:]:\n",
    "        results[i][4] = round(newData[2]['UNRATE'].iloc[i], 2)\n",
    "    else:\n",
    "        while position3 <= len(newData[2]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[2]['Date'].iloc[position3][:2]) and (GDP['Date'].iloc[i][-4:] == newData[2]['Date'].iloc[position3][-4:]):\n",
    "                results[i][4] = round(newData[2]['UNRATE'].iloc[position3], 2)\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[2]['Date'].iloc[position3])\n",
    "                break\n",
    "            else:\n",
    "                position3 = position3 + 1\n",
    "    if GDP['Date'].iloc[i][:2] == newData[3]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[3]['Date'].iloc[i][-4:]:\n",
    "        results[i][5] = round(newData[3]['NFCI'].iloc[i], 2)\n",
    "    else:\n",
    "        while position4 <= len(newData[3]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[3]['Date'].iloc[position4][:2]) and (GDP['Date'].iloc[i][-4:] == newData[3]['Date'].iloc[position4][-4:]):\n",
    "                results[i][5] = round(newData[3]['NFCI'].iloc[position4], 2)\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[3]['Date'].iloc[position4])\n",
    "                break\n",
    "            else:\n",
    "                position4 = position4 + 1    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[4]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[4]['Date'].iloc[i][-4:]:\n",
    "        if newData[4]['USDindex'].iloc[i] == '.':\n",
    "            results[i][6] = newData[4]['USDindex'].iloc[position5 + 1]\n",
    "            # print(GDP['Date'].iloc[i])\n",
    "            # print(newData[4]['Date'].iloc[i])\n",
    "        else:\n",
    "            results[i][6] = newData[4]['USDindex'].iloc[position5]\n",
    "    else:\n",
    "        while position5 <= len(newData[4]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[4]['Date'].iloc[position5][:2]) and (GDP['Date'].iloc[i][-4:] == newData[4]['Date'].iloc[position5][-4:]):\n",
    "                # Test if newData[4]['USDindex'].iloc[position5] == '.'\n",
    "                # if so, take the next one from it\n",
    "                if newData[4]['USDindex'].iloc[position5] == '.':\n",
    "                    results[i][6] = newData[4]['USDindex'].iloc[position5 + 1]\n",
    "                else:\n",
    "                    results[i][6] = newData[4]['USDindex'].iloc[position5]                    \n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[4]['Date'].iloc[position5])\n",
    "                break \n",
    "            else:\n",
    "                position5 = position5 + 1\n",
    "    if GDP['Date'].iloc[i][:2] == newData[5]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[5]['Date'].iloc[i][-4:]:\n",
    "        results[i][7] = round(newData[5]['ManufacturingConfidence'].iloc[i], 2)\n",
    "    else:\n",
    "        while position6 <= len(newData[5]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[5]['Date'].iloc[position6][:2]) and (GDP['Date'].iloc[i][-4:] == newData[5]['Date'].iloc[position6][-4:]):\n",
    "                results[i][7] = round(newData[5]['ManufacturingConfidence'].iloc[position6], 2)\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[5]['Date'].iloc[position6])\n",
    "                break\n",
    "            else:\n",
    "                position6 = position6 + 1\n",
    "    if GDP['Date'].iloc[i][:2] == newData[6]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[6]['Date'].iloc[i][-4:]:\n",
    "        results[i][8] = round(newData[6]['HousePriceIndex'].iloc[i], 2)\n",
    "    else:\n",
    "        while position7 <= len(newData[6]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[6]['Date'].iloc[position7][:2]) and (GDP['Date'].iloc[i][-4:] == newData[6]['Date'].iloc[position7][-4:]):\n",
    "                results[i][8] = round(newData[6]['HousePriceIndex'].iloc[position7], 2)\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[6]['Date'].iloc[position7])\n",
    "                break\n",
    "            else:\n",
    "                position7 = position7 + 1\n",
    "    if GDP['Date'].iloc[i][:2] == newData[7]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[7]['Date'].iloc[i][-4:]:\n",
    "        results[i][9] = newData[7]['ConsumerSentiment'].iloc[i]\n",
    "    else:\n",
    "        while position8 <= len(newData[7]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[7]['Date'].iloc[position8][:2]) and (GDP['Date'].iloc[i][-4:] == newData[7]['Date'].iloc[position8][-4:]):\n",
    "                results[i][9] = newData[7]['ConsumerSentiment'].iloc[position8]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[7]['Date'].iloc[position8])\n",
    "                break\n",
    "            else:\n",
    "                position8 = position8 + 1\n",
    "    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[8]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[8]['Date'].iloc[i][-4:]:\n",
    "        results[i][10] = newData[8]['PeopleOutputPerHour'].iloc[i]\n",
    "    else:\n",
    "        while position9 <= len(newData[8]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[8]['Date'].iloc[position9][:2]) and (GDP['Date'].iloc[i][-4:] == newData[8]['Date'].iloc[position9][-4:]):\n",
    "                results[i][10] = newData[8]['PeopleOutputPerHour'].iloc[position9]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[8]['Date'].iloc[position9])\n",
    "                break\n",
    "            else:\n",
    "                position9 = position9 + 1\n",
    "    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[9]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[9]['Date'].iloc[i][-4:]:\n",
    "        results[i][11] = newData[9]['GS10'].iloc[i]\n",
    "    else:\n",
    "        while position10 <= len(newData[9]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[9]['Date'].iloc[position10][:2]) and (GDP['Date'].iloc[i][-4:] == newData[9]['Date'].iloc[position10][-4:]):\n",
    "                results[i][11] = newData[9]['GS10'].iloc[position10]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[9]['Date'].iloc[position10])\n",
    "                break\n",
    "            else:\n",
    "                position10 = position10 + 1\n",
    "    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[10]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[10]['Date'].iloc[i][-4:]:\n",
    "        results[i][12] = newData[10]['FEDFUNDS'].iloc[i]\n",
    "    else:\n",
    "        while position11 <= len(newData[10]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[10]['Date'].iloc[position11][:2]) and (GDP['Date'].iloc[i][-4:] == newData[10]['Date'].iloc[position11][-4:]):\n",
    "                results[i][12] = newData[10]['FEDFUNDS'].iloc[position11]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[10]['Date'].iloc[position11])\n",
    "                break\n",
    "            else:\n",
    "                position11 = position11 + 1\n",
    "    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[11]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[11]['Date'].iloc[i][-4:]:\n",
    "        results[i][13] = newData[11]['USNIM'].iloc[i]\n",
    "    else:\n",
    "        while position12 <= len(newData[11]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[11]['Date'].iloc[position12][:2]) and (GDP['Date'].iloc[i][-4:] == newData[11]['Date'].iloc[position12][-4:]):\n",
    "                results[i][13] = newData[11]['USNIM'].iloc[position12]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[11]['Date'].iloc[position12])\n",
    "                break\n",
    "            else:\n",
    "                position12 = position12 + 1\n",
    "    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[12]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[12]['Date'].iloc[i][-4:]:\n",
    "        results[i][14] = newData[12]['GEXPND_GDP'].iloc[i] \n",
    "    else:\n",
    "        while position13 <= len(newData[12]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[12]['Date'].iloc[position13][:2]) and (GDP['Date'].iloc[i][-4:] == newData[12]['Date'].iloc[position13][-4:]):\n",
    "                results[i][14] = newData[12]['GEXPND_GDP'].iloc[position13]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[12]['Date'].iloc[position13])\n",
    "                break\n",
    "            else:\n",
    "                position13 = position13 + 1\n",
    "    \n",
    "    if GDP['Date'].iloc[i][:2] == newData[13]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[13]['Date'].iloc[i][-4:]:\n",
    "        results[i][15] = newData[13]['CorporateProfits'].iloc[i]\n",
    "    else:\n",
    "        while position14 <= len(newData[13]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[13]['Date'].iloc[position14][:2]) and (GDP['Date'].iloc[i][-4:] == newData[13]['Date'].iloc[position14][-4:]):\n",
    "                results[i][15] = newData[13]['CorporateProfits'].iloc[position14]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[13]['Date'].iloc[position14])\n",
    "                break\n",
    "            else:\n",
    "                position14 = position14 + 1\n",
    "                \n",
    "    if GDP['Date'].iloc[i][:2] == newData[14]['Date'].iloc[i][:2] and GDP['Date'].iloc[i][-4:] == newData[14]['Date'].iloc[i][-4:]:\n",
    "        results[i][16] = newData[14]['VIX'].iloc[i]\n",
    "    else:\n",
    "        while position15 <= len(newData[14]):\n",
    "            if (GDP['Date'].iloc[i][:2] == newData[14]['Date'].iloc[position15][:2]) and (GDP['Date'].iloc[i][-4:] == newData[14]['Date'].iloc[position15][-4:]):\n",
    "                if newData[14]['VIX'].iloc[position15] == '.':\n",
    "                    results[i][16] = newData[14]['VIX'].iloc[position15 + 2]\n",
    "                else:\n",
    "                    results[i][16] = newData[14]['VIX'].iloc[position15]\n",
    "                # print(GDP['Date'].iloc[i])\n",
    "                # print(newData[14]['Date'].iloc[position15])\n",
    "                break\n",
    "            else:\n",
    "                position15 = position15 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = pd.DataFrame(results)\n",
    "finalData.columns = ['Date', 'GDP', 'SP500', 'T10T3', 'uRate', 'nfci', 'USDIndex',\n",
    "           'ManufacturingConfidence', 'HousePriceIndex', 'ConsumerSentiment',\n",
    "          'PeopleOutputPerHour', 'GS10', 'FEDFUNDS', 'USNIM', 'govtToGDP', 'CorporateProfits', 'VIX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/1/1990\n",
      "338.700012\n",
      "7/1/1990\n",
      "359.540009\n",
      "10/1/1990\n",
      "314.940002\n",
      "1/1/1991\n",
      "326.450012\n",
      "4/1/1991\n",
      "371.299988\n",
      "7/1/1991\n",
      "377.920013\n",
      "10/1/1991\n",
      "389.200012\n",
      "1/1/1992\n",
      "417.26001\n",
      "4/1/1992\n",
      "404.230011\n",
      "7/1/1992\n",
      "412.880005\n",
      "10/1/1992\n",
      "416.290009\n",
      "1/1/1993\n",
      "435.380005\n",
      "4/1/1993\n",
      "450.299988\n",
      "7/1/1993\n",
      "449.01998899999995\n",
      "10/1/1993\n",
      "461.27999900000003\n",
      "1/1/1994\n",
      "465.44000199999994\n",
      "4/1/1994\n",
      "438.920013\n",
      "7/1/1994\n",
      "446.200012\n",
      "10/1/1994\n",
      "461.73999000000003\n",
      "1/1/1995\n",
      "459.10998499999994\n",
      "4/1/1995\n",
      "501.85000599999995\n",
      "7/1/1995\n",
      "547.090027\n",
      "10/1/1995\n",
      "581.719971\n",
      "1/1/1996\n",
      "620.72998\n",
      "4/1/1996\n",
      "653.72998\n",
      "7/1/1996\n",
      "675.880005\n",
      "10/1/1996\n",
      "689.080017\n",
      "1/1/1997\n",
      "737.01001\n",
      "4/1/1997\n",
      "759.6400150000001\n",
      "7/1/1997\n",
      "891.0300289999999\n",
      "10/1/1997\n",
      "955.409973\n",
      "1/1/1998\n",
      "975.0399779999999\n",
      "4/1/1998\n",
      "1108.150024\n",
      "7/1/1998\n",
      "1148.560059\n",
      "10/1/1998\n",
      "986.3900150000001\n",
      "1/1/1999\n",
      "1228.099976\n",
      "4/1/1999\n",
      "1293.719971\n",
      "7/1/1999\n",
      "1380.959961\n",
      "10/1/1999\n",
      "1282.810059\n",
      "1/1/2000\n",
      "1455.219971\n",
      "4/1/2000\n",
      "1505.969971\n",
      "7/1/2000\n",
      "1469.540039\n",
      "10/1/2000\n",
      "1436.22998\n",
      "1/1/2001\n",
      "1283.27002\n",
      "4/1/2001\n",
      "1145.869995\n",
      "7/1/2001\n",
      "1236.719971\n",
      "10/1/2001\n",
      "1038.550049\n",
      "1/1/2002\n",
      "1154.670044\n",
      "4/1/2002\n",
      "1146.540039\n",
      "7/1/2002\n",
      "968.650024\n",
      "10/1/2002\n",
      "847.909973\n",
      "1/1/2003\n",
      "909.0300289999999\n",
      "4/1/2003\n",
      "858.4799800000001\n",
      "7/1/2003\n",
      "982.320007\n",
      "10/1/2003\n",
      "1018.2199710000001\n",
      "1/1/2004\n",
      "1108.47998\n",
      "4/1/2004\n",
      "1132.170044\n",
      "7/1/2004\n",
      "1128.939941\n",
      "10/1/2004\n",
      "1131.5\n",
      "1/1/2005\n",
      "1202.079956\n",
      "4/1/2005\n",
      "1172.920044\n",
      "7/1/2005\n",
      "1194.439941\n",
      "10/1/2005\n",
      "1226.699951\n",
      "1/1/2006\n",
      "1268.800049\n",
      "4/1/2006\n",
      "1297.810059\n",
      "7/1/2006\n",
      "1280.189941\n",
      "10/1/2006\n",
      "1331.319946\n",
      "1/1/2007\n",
      "1416.599976\n",
      "4/1/2007\n",
      "1424.550049\n",
      "7/1/2007\n",
      "1519.430054\n",
      "10/1/2007\n",
      "1547.040039\n",
      "1/1/2008\n",
      "1447.160034\n",
      "4/1/2008\n",
      "1370.180054\n",
      "7/1/2008\n",
      "1284.910034\n",
      "10/1/2008\n",
      "1161.060059\n",
      "1/1/2009\n",
      "931.7999880000001\n",
      "4/1/2009\n",
      "811.080017\n",
      "7/1/2009\n",
      "923.330017\n",
      "10/1/2009\n",
      "1029.849976\n",
      "1/1/2010\n",
      "1132.98999\n",
      "4/1/2010\n",
      "1178.099976\n",
      "7/1/2010\n",
      "1027.369995\n",
      "10/1/2010\n",
      "1146.23999\n",
      "1/1/2011\n",
      "1271.869995\n",
      "4/1/2011\n",
      "1332.410034\n",
      "7/1/2011\n",
      "1339.670044\n",
      "10/1/2011\n",
      "1099.22998\n",
      "1/1/2012\n",
      "1277.060059\n",
      "4/1/2012\n",
      "1419.040039\n",
      "7/1/2012\n",
      "1365.51001\n",
      "10/1/2012\n",
      "1444.48999\n",
      "1/1/2013\n",
      "1462.420044\n",
      "4/1/2013\n",
      "1562.170044\n",
      "7/1/2013\n",
      "1614.959961\n",
      "10/1/2013\n",
      "1695.0\n",
      "1/1/2014\n",
      "1831.97998\n",
      "4/1/2014\n",
      "1885.52002\n",
      "7/1/2014\n",
      "1973.319946\n",
      "10/1/2014\n",
      "1946.160034\n",
      "1/1/2015\n",
      "2058.199951\n",
      "4/1/2015\n",
      "2059.689941\n",
      "7/1/2015\n",
      "2077.419922\n",
      "10/1/2015\n",
      "1923.819946\n",
      "1/1/2016\n",
      "2012.660034\n",
      "4/1/2016\n",
      "2072.780029\n",
      "7/1/2016\n",
      "2102.949951\n",
      "10/1/2016\n",
      "2161.199951\n",
      "1/1/2017\n",
      "2257.830078\n",
      "4/1/2017\n",
      "2358.840088\n",
      "7/1/2017\n",
      "2429.01001\n",
      "10/1/2017\n",
      "2529.1201170000004\n",
      "1/1/2018\n",
      "2695.810059\n",
      "4/1/2018\n",
      "2581.8798829999996\n",
      "7/1/2018\n",
      "2726.709961\n",
      "10/1/2018\n",
      "2924.590088\n"
     ]
    }
   ],
   "source": [
    "# 20% or a larger drawdown from last stock market index top\n",
    "# Using S&P 500 due to US market data ease of gathering. US around 50% of MSCI indexes\n",
    "# SP500\n",
    "\n",
    "spDay = 0\n",
    "spFirstDayOfQuarter = 0\n",
    "spLastDayOfQuarter = 0\n",
    "spMax = SP500['SP500'].iloc[0]\n",
    "spMaxList = []\n",
    "spNewMax = [] # 0 or 1\n",
    "spBelowMax = [] # look at quarter end vs all time high\n",
    "spQuarterReturn = []\n",
    "\n",
    "spMaxQuarterDrawdown = []\n",
    "\n",
    "# Something is still wrong with quarter max/min. Need to investigate\n",
    "spQuarterMax = []\n",
    "spQuarterMin = []\n",
    "# need to figure out how to classify bear market\n",
    "\n",
    "for i in range(1, len(finalData)):\n",
    "    print(finalData['Date'].iloc[i])\n",
    "    maxCheck = None\n",
    "    while spDay <= len(SP500):\n",
    "        if (finalData['Date'].iloc[i][:2] == SP500['Date'].iloc[spDay][:2]) and (finalData['Date'].iloc[i][-4:] == SP500['Date'].iloc[spDay][-4:]):\n",
    "            print(SP500['SP500'].iloc[spDay])    \n",
    "            spMaxList.append(spMax)\n",
    "            if maxCheck:\n",
    "                spNewMax.append(1)\n",
    "            else:\n",
    "                spNewMax.append(0)            \n",
    "            #print((SP500['SP500'].iloc[spDay] / SP500['SP500'].iloc[spFirstDayOfQuarter]) - 1)\n",
    "            spQuarterReturn.append(SP500['SP500'].iloc[spDay] / SP500['SP500'].iloc[spFirstDayOfQuarter] - 1)\n",
    "            quarterMax = SP500['SP500'].iloc[spFirstDayOfQuarter]\n",
    "            quarterMin = SP500['SP500'].iloc[spFirstDayOfQuarter]\n",
    "            checkValue = SP500['SP500'].iloc[spFirstDayOfQuarter]\n",
    "            for j in range(spFirstDayOfQuarter, spDay): \n",
    "                if SP500['SP500'].iloc[j] > quarterMax:\n",
    "                    quarterMax = SP500['SP500'].iloc[j]\n",
    "                if SP500['SP500'].iloc[j] < quarterMin:\n",
    "                    quarterMin = SP500['SP500'].iloc[j]\n",
    "                    checkValue = quarterMin / quarterMax - 1\n",
    "            spQuarterMax.append(quarterMax)\n",
    "            spQuarterMin.append(quarterMin)\n",
    "            spMaxQuarterDrawdown.append(checkValue)\n",
    "            spBelowMax.append((quarterMin / spMax) - 1)\n",
    "            spFirstDayOfQuarter = spDay\n",
    "            break\n",
    "        else:\n",
    "            spDay = spDay + 1\n",
    "            if SP500['SP500'].iloc[spDay] > spMax:\n",
    "                spMax = SP500['SP500'].iloc[spDay]\n",
    "                maxCheck = True            \n",
    "            #spQuarterMaxDrawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = finalData.iloc[1:]\n",
    "\n",
    "finalData['spHistoricalMax'] = spMaxList\n",
    "finalData['spMaxAchieved'] = spNewMax\n",
    "finalData['spBelowMax'] = spBelowMax\n",
    "finalData['spQuarterPerformance'] = spQuarterReturn\n",
    "finalData['QuarterMax'] = spQuarterMax\n",
    "finalData['QuarterMin'] = spQuarterMin\n",
    "finalData['spMaxQuarterDrawdown'] = spMaxQuarterDrawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpMove = []\n",
    "spMove = []\n",
    "gdpMoveQoverQ = [] # did gdp grow from the last quarter to the next one\n",
    "gdpMoveYoverY = [] # did gdp grow from last year's quarter to this year's quarter\n",
    "\n",
    "for i in range(1, len(finalData)):\n",
    "    #print(finalData['Date'].iloc[i], 'GDP', finalData['GDP'].iloc[i] - finalData['GDP'].iloc[i - 1])\n",
    "    if (finalData['GDP'].iloc[i] - finalData['GDP'].iloc[i - 1]) > 0.0:\n",
    "        gdpMove.append(1)\n",
    "    else:\n",
    "        gdpMove.append(0)        \n",
    "    #print(finalData['Date'].iloc[i], 'SP500', finalData['SP500'].iloc[i] - finalData['SP500'].iloc[i - 1])\n",
    "    if (finalData['SP500'].iloc[i] - finalData['SP500'].iloc[i - 1]) > 0.0:\n",
    "        spMove.append(1)\n",
    "    else:\n",
    "        spMove.append(0)\n",
    "    if i >= 1:\n",
    "        gdpMoveQoverQ.append((finalData['GDP'].iloc[i] / finalData['GDP'].iloc[i - 1]) - 1)\n",
    "    if i >= 4:\n",
    "        gdpMoveYoverY.append((finalData['GDP'].iloc[i] / finalData['GDP'].iloc[i - 4]) - 1)\n",
    "        \n",
    "finalData = finalData.iloc[1:]\n",
    "        \n",
    "#finalData['gdpMove'] = gdpMove\n",
    "finalData['spMove'] = spMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalData['GDP'].iloc[len(finalData) - 1] / (111.19 / 100)\n",
    "gdpGrowth = pd.read_csv('Data/gdpGrowth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "finalData['gdpGrowth'] = gdpGrowth['GDPgrowth']\n",
    "finalData['gdpGrowth'].iloc[len(finalData) - 1] = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>T10T3</th>\n",
       "      <th>uRate</th>\n",
       "      <th>nfci</th>\n",
       "      <th>USDIndex</th>\n",
       "      <th>ManufacturingConfidence</th>\n",
       "      <th>HousePriceIndex</th>\n",
       "      <th>ConsumerSentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>VIX</th>\n",
       "      <th>spHistoricalMax</th>\n",
       "      <th>spMaxAchieved</th>\n",
       "      <th>spBelowMax</th>\n",
       "      <th>spQuarterPerformance</th>\n",
       "      <th>QuarterMax</th>\n",
       "      <th>QuarterMin</th>\n",
       "      <th>spMaxQuarterDrawdown</th>\n",
       "      <th>spMove</th>\n",
       "      <th>gdpGrowth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/1/1990</td>\n",
       "      <td>6015.12</td>\n",
       "      <td>359.54</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>91.5346</td>\n",
       "      <td>98.75</td>\n",
       "      <td>165.84</td>\n",
       "      <td>88.2</td>\n",
       "      <td>...</td>\n",
       "      <td>16.26</td>\n",
       "      <td>367.399994</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.104219</td>\n",
       "      <td>0.061529</td>\n",
       "      <td>367.399994</td>\n",
       "      <td>329.109985</td>\n",
       "      <td>-0.045339</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1990</td>\n",
       "      <td>6004.73</td>\n",
       "      <td>314.94</td>\n",
       "      <td>1.34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>86.2694</td>\n",
       "      <td>97.85</td>\n",
       "      <td>165.20</td>\n",
       "      <td>63.9</td>\n",
       "      <td>...</td>\n",
       "      <td>28.06</td>\n",
       "      <td>368.950012</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.184253</td>\n",
       "      <td>-0.124047</td>\n",
       "      <td>368.950012</td>\n",
       "      <td>300.970001</td>\n",
       "      <td>-0.184253</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/1991</td>\n",
       "      <td>6035.18</td>\n",
       "      <td>326.45</td>\n",
       "      <td>1.31</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>84.878</td>\n",
       "      <td>97.13</td>\n",
       "      <td>166.57</td>\n",
       "      <td>66.8</td>\n",
       "      <td>...</td>\n",
       "      <td>27.93</td>\n",
       "      <td>368.950012</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.199187</td>\n",
       "      <td>0.036547</td>\n",
       "      <td>331.750000</td>\n",
       "      <td>295.459991</td>\n",
       "      <td>-0.062657</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/1/1991</td>\n",
       "      <td>6126.86</td>\n",
       "      <td>371.30</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>90.2577</td>\n",
       "      <td>97.82</td>\n",
       "      <td>167.70</td>\n",
       "      <td>81.8</td>\n",
       "      <td>...</td>\n",
       "      <td>17.42</td>\n",
       "      <td>376.720001</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.173153</td>\n",
       "      <td>0.137387</td>\n",
       "      <td>376.720001</td>\n",
       "      <td>311.489990</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/1/1991</td>\n",
       "      <td>6205.94</td>\n",
       "      <td>377.92</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>92.8816</td>\n",
       "      <td>99.58</td>\n",
       "      <td>167.99</td>\n",
       "      <td>82.9</td>\n",
       "      <td>...</td>\n",
       "      <td>18.64</td>\n",
       "      <td>390.450012</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.056038</td>\n",
       "      <td>0.017829</td>\n",
       "      <td>390.450012</td>\n",
       "      <td>368.570007</td>\n",
       "      <td>-0.056038</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/1/1991</td>\n",
       "      <td>6264.54</td>\n",
       "      <td>389.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>88.2307</td>\n",
       "      <td>99.78</td>\n",
       "      <td>170.35</td>\n",
       "      <td>78.3</td>\n",
       "      <td>...</td>\n",
       "      <td>14.81</td>\n",
       "      <td>396.640015</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.058769</td>\n",
       "      <td>0.029848</td>\n",
       "      <td>396.640015</td>\n",
       "      <td>373.329987</td>\n",
       "      <td>-0.012145</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/1/1992</td>\n",
       "      <td>6363.10</td>\n",
       "      <td>417.26</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>84.1381</td>\n",
       "      <td>99.11</td>\n",
       "      <td>171.67</td>\n",
       "      <td>67.5</td>\n",
       "      <td>...</td>\n",
       "      <td>18.75</td>\n",
       "      <td>417.260010</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.072097</td>\n",
       "      <td>417.089996</td>\n",
       "      <td>375.220001</td>\n",
       "      <td>-0.055837</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4/1/1992</td>\n",
       "      <td>6470.76</td>\n",
       "      <td>404.23</td>\n",
       "      <td>3.35</td>\n",
       "      <td>7.4</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>89.7026</td>\n",
       "      <td>100.15</td>\n",
       "      <td>171.64</td>\n",
       "      <td>77.2</td>\n",
       "      <td>...</td>\n",
       "      <td>16.48</td>\n",
       "      <td>420.769989</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.042232</td>\n",
       "      <td>-0.031228</td>\n",
       "      <td>420.769989</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>-0.042232</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7/1/1992</td>\n",
       "      <td>6566.64</td>\n",
       "      <td>412.88</td>\n",
       "      <td>3.47</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>84.6773</td>\n",
       "      <td>100.05</td>\n",
       "      <td>173.60</td>\n",
       "      <td>76.6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.34</td>\n",
       "      <td>420.769989</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.062433</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>418.489990</td>\n",
       "      <td>394.500000</td>\n",
       "      <td>-0.027343</td>\n",
       "      <td>1</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10/1/1992</td>\n",
       "      <td>6680.80</td>\n",
       "      <td>416.29</td>\n",
       "      <td>3.56</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>84.284</td>\n",
       "      <td>99.62</td>\n",
       "      <td>174.47</td>\n",
       "      <td>73.3</td>\n",
       "      <td>...</td>\n",
       "      <td>16.31</td>\n",
       "      <td>425.269989</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.037882</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>425.269989</td>\n",
       "      <td>409.160004</td>\n",
       "      <td>-0.011309</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/1/1993</td>\n",
       "      <td>6729.46</td>\n",
       "      <td>435.38</td>\n",
       "      <td>3.41</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>92.1416</td>\n",
       "      <td>100.37</td>\n",
       "      <td>174.54</td>\n",
       "      <td>89.3</td>\n",
       "      <td>...</td>\n",
       "      <td>13.35</td>\n",
       "      <td>441.279999</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.087518</td>\n",
       "      <td>0.045857</td>\n",
       "      <td>441.279999</td>\n",
       "      <td>402.660004</td>\n",
       "      <td>-0.032742</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4/1/1993</td>\n",
       "      <td>6808.94</td>\n",
       "      <td>450.30</td>\n",
       "      <td>3.10</td>\n",
       "      <td>7.1</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>88.9357</td>\n",
       "      <td>99.64</td>\n",
       "      <td>176.20</td>\n",
       "      <td>85.6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.02</td>\n",
       "      <td>456.329987</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.059781</td>\n",
       "      <td>0.034269</td>\n",
       "      <td>456.329987</td>\n",
       "      <td>429.049988</td>\n",
       "      <td>-0.014539</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7/1/1993</td>\n",
       "      <td>6882.10</td>\n",
       "      <td>449.02</td>\n",
       "      <td>2.74</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>89.6074</td>\n",
       "      <td>99.33</td>\n",
       "      <td>177.62</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>11.51</td>\n",
       "      <td>456.329987</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.049942</td>\n",
       "      <td>-0.002843</td>\n",
       "      <td>453.850006</td>\n",
       "      <td>433.540009</td>\n",
       "      <td>-0.037220</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10/1/1993</td>\n",
       "      <td>7013.74</td>\n",
       "      <td>461.28</td>\n",
       "      <td>2.36</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>89.7271</td>\n",
       "      <td>99.91</td>\n",
       "      <td>179.09</td>\n",
       "      <td>82.7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.83</td>\n",
       "      <td>463.559998</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.047739</td>\n",
       "      <td>0.027304</td>\n",
       "      <td>463.559998</td>\n",
       "      <td>441.429993</td>\n",
       "      <td>-0.016903</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/1/1994</td>\n",
       "      <td>7115.65</td>\n",
       "      <td>465.44</td>\n",
       "      <td>2.76</td>\n",
       "      <td>6.6</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>92.4979</td>\n",
       "      <td>100.57</td>\n",
       "      <td>180.22</td>\n",
       "      <td>94.3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.57</td>\n",
       "      <td>470.940002</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.028560</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>470.940002</td>\n",
       "      <td>457.489990</td>\n",
       "      <td>-0.025580</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4/1/1994</td>\n",
       "      <td>7246.93</td>\n",
       "      <td>438.92</td>\n",
       "      <td>3.34</td>\n",
       "      <td>6.4</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>90.7396</td>\n",
       "      <td>100.90</td>\n",
       "      <td>181.31</td>\n",
       "      <td>92.6</td>\n",
       "      <td>...</td>\n",
       "      <td>18.13</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.075622</td>\n",
       "      <td>-0.056978</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>445.549988</td>\n",
       "      <td>-0.075622</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7/1/1994</td>\n",
       "      <td>7331.08</td>\n",
       "      <td>446.20</td>\n",
       "      <td>3.02</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>87.3413</td>\n",
       "      <td>101.11</td>\n",
       "      <td>182.06</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>14.36</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.089378</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>462.369995</td>\n",
       "      <td>438.920013</td>\n",
       "      <td>438.920013</td>\n",
       "      <td>1</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10/1/1994</td>\n",
       "      <td>7455.29</td>\n",
       "      <td>461.74</td>\n",
       "      <td>2.61</td>\n",
       "      <td>5.8</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>85.9581</td>\n",
       "      <td>101.21</td>\n",
       "      <td>181.90</td>\n",
       "      <td>92.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.44</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.074419</td>\n",
       "      <td>0.034827</td>\n",
       "      <td>476.070007</td>\n",
       "      <td>446.130005</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/1/1995</td>\n",
       "      <td>7522.29</td>\n",
       "      <td>459.11</td>\n",
       "      <td>1.93</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>87.466</td>\n",
       "      <td>100.67</td>\n",
       "      <td>182.86</td>\n",
       "      <td>97.6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.53</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.075830</td>\n",
       "      <td>-0.005696</td>\n",
       "      <td>473.769989</td>\n",
       "      <td>445.450012</td>\n",
       "      <td>-0.059776</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4/1/1995</td>\n",
       "      <td>7581.00</td>\n",
       "      <td>501.85</td>\n",
       "      <td>1.20</td>\n",
       "      <td>5.8</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>81.3046</td>\n",
       "      <td>99.38</td>\n",
       "      <td>185.85</td>\n",
       "      <td>92.5</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5</td>\n",
       "      <td>503.899994</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.088887</td>\n",
       "      <td>0.093093</td>\n",
       "      <td>503.899994</td>\n",
       "      <td>459.109985</td>\n",
       "      <td>459.109985</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7/1/1995</td>\n",
       "      <td>7683.12</td>\n",
       "      <td>547.09</td>\n",
       "      <td>0.53</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>80.4226</td>\n",
       "      <td>98.93</td>\n",
       "      <td>188.72</td>\n",
       "      <td>94.4</td>\n",
       "      <td>...</td>\n",
       "      <td>11.57</td>\n",
       "      <td>551.070007</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.089317</td>\n",
       "      <td>0.090146</td>\n",
       "      <td>551.070007</td>\n",
       "      <td>501.850006</td>\n",
       "      <td>501.850006</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10/1/1995</td>\n",
       "      <td>7772.59</td>\n",
       "      <td>581.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>84.1324</td>\n",
       "      <td>98.66</td>\n",
       "      <td>190.19</td>\n",
       "      <td>90.2</td>\n",
       "      <td>...</td>\n",
       "      <td>13.95</td>\n",
       "      <td>586.770020</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.067624</td>\n",
       "      <td>0.063298</td>\n",
       "      <td>586.770020</td>\n",
       "      <td>547.090027</td>\n",
       "      <td>547.090027</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1/1/1996</td>\n",
       "      <td>7868.47</td>\n",
       "      <td>620.73</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>85.2252</td>\n",
       "      <td>98.43</td>\n",
       "      <td>192.34</td>\n",
       "      <td>89.3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.1</td>\n",
       "      <td>621.690002</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.072335</td>\n",
       "      <td>0.067060</td>\n",
       "      <td>621.690002</td>\n",
       "      <td>576.719971</td>\n",
       "      <td>-0.023584</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4/1/1996</td>\n",
       "      <td>8032.84</td>\n",
       "      <td>653.73</td>\n",
       "      <td>1.11</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>86.7265</td>\n",
       "      <td>99.06</td>\n",
       "      <td>192.67</td>\n",
       "      <td>92.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17.9</td>\n",
       "      <td>661.450012</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.095200</td>\n",
       "      <td>0.053163</td>\n",
       "      <td>661.450012</td>\n",
       "      <td>598.479980</td>\n",
       "      <td>-0.036760</td>\n",
       "      <td>1</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7/1/1996</td>\n",
       "      <td>8131.41</td>\n",
       "      <td>675.88</td>\n",
       "      <td>1.47</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>87.6481</td>\n",
       "      <td>99.55</td>\n",
       "      <td>193.53</td>\n",
       "      <td>94.7</td>\n",
       "      <td>...</td>\n",
       "      <td>13.78</td>\n",
       "      <td>678.510010</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.069756</td>\n",
       "      <td>0.033883</td>\n",
       "      <td>678.510010</td>\n",
       "      <td>631.179993</td>\n",
       "      <td>-0.037659</td>\n",
       "      <td>1</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10/1/1996</td>\n",
       "      <td>8259.77</td>\n",
       "      <td>689.08</td>\n",
       "      <td>1.55</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>87.9329</td>\n",
       "      <td>99.67</td>\n",
       "      <td>195.04</td>\n",
       "      <td>96.5</td>\n",
       "      <td>...</td>\n",
       "      <td>17.05</td>\n",
       "      <td>689.080017</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.090599</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>687.330017</td>\n",
       "      <td>626.650024</td>\n",
       "      <td>-0.072838</td>\n",
       "      <td>1</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1/1/1997</td>\n",
       "      <td>8362.66</td>\n",
       "      <td>737.01</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>88.7042</td>\n",
       "      <td>100.13</td>\n",
       "      <td>196.66</td>\n",
       "      <td>97.4</td>\n",
       "      <td>...</td>\n",
       "      <td>19.13</td>\n",
       "      <td>757.030029</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.089759</td>\n",
       "      <td>0.069556</td>\n",
       "      <td>757.030029</td>\n",
       "      <td>689.080017</td>\n",
       "      <td>689.080017</td>\n",
       "      <td>1</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4/1/1997</td>\n",
       "      <td>8518.83</td>\n",
       "      <td>759.64</td>\n",
       "      <td>1.58</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>93.0883</td>\n",
       "      <td>100.23</td>\n",
       "      <td>198.31</td>\n",
       "      <td>101.4</td>\n",
       "      <td>...</td>\n",
       "      <td>20.84</td>\n",
       "      <td>816.289978</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.097122</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>816.289978</td>\n",
       "      <td>737.010010</td>\n",
       "      <td>737.010010</td>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7/1/1997</td>\n",
       "      <td>8662.82</td>\n",
       "      <td>891.03</td>\n",
       "      <td>1.27</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>92.6502</td>\n",
       "      <td>100.65</td>\n",
       "      <td>201.04</td>\n",
       "      <td>107.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>898.700012</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.179203</td>\n",
       "      <td>0.172964</td>\n",
       "      <td>898.700012</td>\n",
       "      <td>737.650024</td>\n",
       "      <td>-0.037161</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10/1/1997</td>\n",
       "      <td>8765.91</td>\n",
       "      <td>955.41</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>94.6308</td>\n",
       "      <td>100.49</td>\n",
       "      <td>203.64</td>\n",
       "      <td>105.6</td>\n",
       "      <td>...</td>\n",
       "      <td>22.32</td>\n",
       "      <td>960.320007</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.072153</td>\n",
       "      <td>0.072253</td>\n",
       "      <td>960.320007</td>\n",
       "      <td>891.030029</td>\n",
       "      <td>891.030029</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>7/1/2011</td>\n",
       "      <td>15591.85</td>\n",
       "      <td>1339.67</td>\n",
       "      <td>3.20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>69.0975</td>\n",
       "      <td>100.07</td>\n",
       "      <td>309.73</td>\n",
       "      <td>63.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.87</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.191502</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>1363.609985</td>\n",
       "      <td>1265.420044</td>\n",
       "      <td>-0.072007</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>10/1/2011</td>\n",
       "      <td>15796.46</td>\n",
       "      <td>1099.23</td>\n",
       "      <td>1.78</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>73.3657</td>\n",
       "      <td>99.69</td>\n",
       "      <td>311.09</td>\n",
       "      <td>60.8</td>\n",
       "      <td>...</td>\n",
       "      <td>45.45</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.284759</td>\n",
       "      <td>-0.179477</td>\n",
       "      <td>1353.219971</td>\n",
       "      <td>1119.459961</td>\n",
       "      <td>-0.172744</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1/1/2012</td>\n",
       "      <td>16019.76</td>\n",
       "      <td>1277.06</td>\n",
       "      <td>1.95</td>\n",
       "      <td>8.3</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>72.9043</td>\n",
       "      <td>99.95</td>\n",
       "      <td>307.81</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>22.22</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.297684</td>\n",
       "      <td>0.161777</td>\n",
       "      <td>1285.089966</td>\n",
       "      <td>1099.229980</td>\n",
       "      <td>1099.229980</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4/1/2012</td>\n",
       "      <td>16152.26</td>\n",
       "      <td>1419.04</td>\n",
       "      <td>2.14</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>72.5836</td>\n",
       "      <td>100.08</td>\n",
       "      <td>306.54</td>\n",
       "      <td>76.4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.64</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.184065</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>1416.510010</td>\n",
       "      <td>1277.060059</td>\n",
       "      <td>1277.060059</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7/1/2012</td>\n",
       "      <td>16257.15</td>\n",
       "      <td>1365.51</td>\n",
       "      <td>1.51</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>74.7085</td>\n",
       "      <td>99.47</td>\n",
       "      <td>310.51</td>\n",
       "      <td>72.3</td>\n",
       "      <td>...</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.183439</td>\n",
       "      <td>-0.037723</td>\n",
       "      <td>1419.040039</td>\n",
       "      <td>1278.040039</td>\n",
       "      <td>-0.099363</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>10/1/2012</td>\n",
       "      <td>16358.86</td>\n",
       "      <td>1444.49</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.8</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>72.7076</td>\n",
       "      <td>99.37</td>\n",
       "      <td>313.02</td>\n",
       "      <td>82.6</td>\n",
       "      <td>...</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.147200</td>\n",
       "      <td>0.057839</td>\n",
       "      <td>1465.770020</td>\n",
       "      <td>1334.760010</td>\n",
       "      <td>-0.028573</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1/1/2013</td>\n",
       "      <td>16569.59</td>\n",
       "      <td>1462.42</td>\n",
       "      <td>1.78</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>73.3738</td>\n",
       "      <td>99.78</td>\n",
       "      <td>314.64</td>\n",
       "      <td>73.8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.56</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.135335</td>\n",
       "      <td>0.012413</td>\n",
       "      <td>1461.400024</td>\n",
       "      <td>1353.329956</td>\n",
       "      <td>-0.073950</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4/1/2013</td>\n",
       "      <td>16637.93</td>\n",
       "      <td>1562.17</td>\n",
       "      <td>1.78</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>76.1008</td>\n",
       "      <td>99.59</td>\n",
       "      <td>319.56</td>\n",
       "      <td>76.4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.58</td>\n",
       "      <td>1569.189941</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.071400</td>\n",
       "      <td>0.068209</td>\n",
       "      <td>1569.189941</td>\n",
       "      <td>1457.150024</td>\n",
       "      <td>-0.006355</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>7/1/2013</td>\n",
       "      <td>16848.75</td>\n",
       "      <td>1614.96</td>\n",
       "      <td>2.46</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>77.4363</td>\n",
       "      <td>100.08</td>\n",
       "      <td>324.53</td>\n",
       "      <td>85.1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.37</td>\n",
       "      <td>1669.160034</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.076416</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>1669.160034</td>\n",
       "      <td>1541.609985</td>\n",
       "      <td>-0.032485</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10/1/2013</td>\n",
       "      <td>17083.14</td>\n",
       "      <td>1695.00</td>\n",
       "      <td>2.64</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>75.2495</td>\n",
       "      <td>100.51</td>\n",
       "      <td>327.26</td>\n",
       "      <td>73.2</td>\n",
       "      <td>...</td>\n",
       "      <td>15.54</td>\n",
       "      <td>1725.520020</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.064583</td>\n",
       "      <td>0.049562</td>\n",
       "      <td>1725.520020</td>\n",
       "      <td>1614.079956</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>17102.93</td>\n",
       "      <td>1831.98</td>\n",
       "      <td>2.93</td>\n",
       "      <td>6.6</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>76.426</td>\n",
       "      <td>100.18</td>\n",
       "      <td>330.16</td>\n",
       "      <td>81.2</td>\n",
       "      <td>...</td>\n",
       "      <td>13.76</td>\n",
       "      <td>1848.359985</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.104368</td>\n",
       "      <td>0.080814</td>\n",
       "      <td>1848.359985</td>\n",
       "      <td>1655.449951</td>\n",
       "      <td>-0.023333</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4/1/2014</td>\n",
       "      <td>17425.77</td>\n",
       "      <td>1885.52</td>\n",
       "      <td>2.73</td>\n",
       "      <td>6.2</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>76.5809</td>\n",
       "      <td>100.42</td>\n",
       "      <td>336.46</td>\n",
       "      <td>84.1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1885.520020</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.076175</td>\n",
       "      <td>0.029225</td>\n",
       "      <td>1878.040039</td>\n",
       "      <td>1741.890015</td>\n",
       "      <td>-0.057613</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7/1/2014</td>\n",
       "      <td>17719.84</td>\n",
       "      <td>1973.32</td>\n",
       "      <td>2.56</td>\n",
       "      <td>6.2</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>75.6811</td>\n",
       "      <td>100.62</td>\n",
       "      <td>341.32</td>\n",
       "      <td>81.8</td>\n",
       "      <td>...</td>\n",
       "      <td>11.15</td>\n",
       "      <td>1973.319946</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.079881</td>\n",
       "      <td>0.046565</td>\n",
       "      <td>1962.869995</td>\n",
       "      <td>1815.689941</td>\n",
       "      <td>-0.039775</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10/1/2014</td>\n",
       "      <td>17838.45</td>\n",
       "      <td>1946.16</td>\n",
       "      <td>2.40</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>80.9928</td>\n",
       "      <td>100.78</td>\n",
       "      <td>344.13</td>\n",
       "      <td>86.9</td>\n",
       "      <td>...</td>\n",
       "      <td>16.71</td>\n",
       "      <td>2011.359985</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.050608</td>\n",
       "      <td>-0.013764</td>\n",
       "      <td>2011.359985</td>\n",
       "      <td>1909.569946</td>\n",
       "      <td>-0.039442</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>17970.42</td>\n",
       "      <td>2058.20</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>85.7577</td>\n",
       "      <td>100.18</td>\n",
       "      <td>347.56</td>\n",
       "      <td>98.1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.92</td>\n",
       "      <td>2090.570068</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109099</td>\n",
       "      <td>0.057570</td>\n",
       "      <td>2090.570068</td>\n",
       "      <td>1862.489990</td>\n",
       "      <td>-0.054041</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>4/1/2015</td>\n",
       "      <td>18221.30</td>\n",
       "      <td>2059.69</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5.4</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>91.7881</td>\n",
       "      <td>99.81</td>\n",
       "      <td>353.68</td>\n",
       "      <td>95.9</td>\n",
       "      <td>...</td>\n",
       "      <td>15.11</td>\n",
       "      <td>2117.389893</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.058903</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>2117.389893</td>\n",
       "      <td>1992.670044</td>\n",
       "      <td>-0.033688</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7/1/2015</td>\n",
       "      <td>18331.09</td>\n",
       "      <td>2077.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>90.4411</td>\n",
       "      <td>99.73</td>\n",
       "      <td>359.16</td>\n",
       "      <td>93.1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.09</td>\n",
       "      <td>2130.820068</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.034344</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>2130.820068</td>\n",
       "      <td>2057.639893</td>\n",
       "      <td>-0.034344</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10/1/2015</td>\n",
       "      <td>18354.37</td>\n",
       "      <td>1923.82</td>\n",
       "      <td>2.05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>91.6013</td>\n",
       "      <td>99.15</td>\n",
       "      <td>362.42</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>22.55</td>\n",
       "      <td>2130.820068</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.123525</td>\n",
       "      <td>-0.073938</td>\n",
       "      <td>2128.280029</td>\n",
       "      <td>1867.609985</td>\n",
       "      <td>-0.122479</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>18409.13</td>\n",
       "      <td>2012.66</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>94.6663</td>\n",
       "      <td>99.03</td>\n",
       "      <td>365.78</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>19.34</td>\n",
       "      <td>2130.820068</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.097146</td>\n",
       "      <td>0.046179</td>\n",
       "      <td>2109.790039</td>\n",
       "      <td>1923.819946</td>\n",
       "      <td>1923.819946</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>4/1/2016</td>\n",
       "      <td>18640.73</td>\n",
       "      <td>2072.78</td>\n",
       "      <td>1.56</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>89.9376</td>\n",
       "      <td>99.59</td>\n",
       "      <td>372.95</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2130.820068</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141608</td>\n",
       "      <td>0.029871</td>\n",
       "      <td>2063.949951</td>\n",
       "      <td>1829.079956</td>\n",
       "      <td>-0.093038</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7/1/2016</td>\n",
       "      <td>18799.65</td>\n",
       "      <td>2102.95</td>\n",
       "      <td>1.18</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>89.892</td>\n",
       "      <td>99.69</td>\n",
       "      <td>379.67</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>14.77</td>\n",
       "      <td>2130.820068</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.061141</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>2119.120117</td>\n",
       "      <td>2000.540039</td>\n",
       "      <td>-0.055957</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10/1/2016</td>\n",
       "      <td>18979.24</td>\n",
       "      <td>2161.20</td>\n",
       "      <td>1.31</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>90.2321</td>\n",
       "      <td>99.75</td>\n",
       "      <td>383.16</td>\n",
       "      <td>87.2</td>\n",
       "      <td>...</td>\n",
       "      <td>13.57</td>\n",
       "      <td>2190.149902</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046389</td>\n",
       "      <td>0.027699</td>\n",
       "      <td>2190.149902</td>\n",
       "      <td>2088.550049</td>\n",
       "      <td>-0.006847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>19162.55</td>\n",
       "      <td>2257.83</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>96.4677</td>\n",
       "      <td>100.58</td>\n",
       "      <td>386.71</td>\n",
       "      <td>98.5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.85</td>\n",
       "      <td>2271.719971</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.082114</td>\n",
       "      <td>0.044711</td>\n",
       "      <td>2271.719971</td>\n",
       "      <td>2085.179932</td>\n",
       "      <td>-0.036272</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4/1/2017</td>\n",
       "      <td>19359.12</td>\n",
       "      <td>2358.84</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>94.2513</td>\n",
       "      <td>100.54</td>\n",
       "      <td>396.70</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>12.38</td>\n",
       "      <td>2395.959961</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.057651</td>\n",
       "      <td>0.044738</td>\n",
       "      <td>2395.959961</td>\n",
       "      <td>2257.830078</td>\n",
       "      <td>2257.830078</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>7/1/2017</td>\n",
       "      <td>19588.07</td>\n",
       "      <td>2429.01</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>90.8407</td>\n",
       "      <td>100.87</td>\n",
       "      <td>403.46</td>\n",
       "      <td>93.4</td>\n",
       "      <td>...</td>\n",
       "      <td>11.22</td>\n",
       "      <td>2453.459961</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.050749</td>\n",
       "      <td>0.029748</td>\n",
       "      <td>2453.459961</td>\n",
       "      <td>2328.949951</td>\n",
       "      <td>-0.013224</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>10/1/2017</td>\n",
       "      <td>19831.83</td>\n",
       "      <td>2529.12</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>88.3967</td>\n",
       "      <td>101.25</td>\n",
       "      <td>407.67</td>\n",
       "      <td>100.7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.45</td>\n",
       "      <td>2529.120117</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.047198</td>\n",
       "      <td>0.041214</td>\n",
       "      <td>2519.360107</td>\n",
       "      <td>2409.750000</td>\n",
       "      <td>-0.009369</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>20041.05</td>\n",
       "      <td>2695.81</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>87.2663</td>\n",
       "      <td>101.32</td>\n",
       "      <td>413.53</td>\n",
       "      <td>95.7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.15</td>\n",
       "      <td>2695.810059</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.061833</td>\n",
       "      <td>0.065908</td>\n",
       "      <td>2690.159912</td>\n",
       "      <td>2529.120117</td>\n",
       "      <td>2529.120117</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>4/1/2018</td>\n",
       "      <td>20411.92</td>\n",
       "      <td>2581.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>86.4032</td>\n",
       "      <td>101.11</td>\n",
       "      <td>423.91</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>23.62</td>\n",
       "      <td>2872.870117</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.101595</td>\n",
       "      <td>-0.042262</td>\n",
       "      <td>2872.870117</td>\n",
       "      <td>2581.000000</td>\n",
       "      <td>-0.101595</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>20658.20</td>\n",
       "      <td>2726.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>90.4184</td>\n",
       "      <td>101.31</td>\n",
       "      <td>430.76</td>\n",
       "      <td>97.9</td>\n",
       "      <td>...</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2872.870117</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.101289</td>\n",
       "      <td>0.056095</td>\n",
       "      <td>2786.850098</td>\n",
       "      <td>2581.879883</td>\n",
       "      <td>2581.879883</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>20865.14</td>\n",
       "      <td>2924.59</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>90.1677</td>\n",
       "      <td>101.13</td>\n",
       "      <td>432.14</td>\n",
       "      <td>98.6</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2930.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074223</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>2930.750000</td>\n",
       "      <td>2713.219971</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       GDP    SP500  T10T3  uRate  nfci USDIndex  \\\n",
       "2     7/1/1990   6015.12   359.54   0.43    5.5 -0.23  91.5346   \n",
       "3    10/1/1990   6004.73   314.94   1.34    5.9  0.25  86.2694   \n",
       "4     1/1/1991   6035.18   326.45   1.31    6.4  0.37   84.878   \n",
       "5     4/1/1991   6126.86   371.30   2.13    6.7 -0.20  90.2577   \n",
       "6     7/1/1991   6205.94   377.92   2.50    6.8 -0.36  92.8816   \n",
       "7    10/1/1991   6264.54   389.20   2.20    7.0 -0.49  88.2307   \n",
       "8     1/1/1992   6363.10   417.26   2.82    7.3 -0.50  84.1381   \n",
       "9     4/1/1992   6470.76   404.23   3.35    7.4 -0.62  89.7026   \n",
       "10    7/1/1992   6566.64   412.88   3.47    7.7 -0.75  84.6773   \n",
       "11   10/1/1992   6680.80   416.29   3.56    7.3 -0.56   84.284   \n",
       "12    1/1/1993   6729.46   435.38   3.41    7.3 -0.74  92.1416   \n",
       "13    4/1/1993   6808.94   450.30   3.10    7.1 -0.75  88.9357   \n",
       "14    7/1/1993   6882.10   449.02   2.74    6.9 -0.88  89.6074   \n",
       "15   10/1/1993   7013.74   461.28   2.36    6.8 -0.85  89.7271   \n",
       "16    1/1/1994   7115.65   465.44   2.76    6.6 -0.88  92.4979   \n",
       "17    4/1/1994   7246.93   438.92   3.34    6.4 -0.71  90.7396   \n",
       "18    7/1/1994   7331.08   446.20   3.02    6.1 -0.69  87.3413   \n",
       "19   10/1/1994   7455.29   461.74   2.61    5.8 -0.68  85.9581   \n",
       "20    1/1/1995   7522.29   459.11   1.93    5.6 -0.52   87.466   \n",
       "21    4/1/1995   7581.00   501.85   1.20    5.8 -0.65  81.3046   \n",
       "22    7/1/1995   7683.12   547.09   0.53    5.7 -0.62  80.4226   \n",
       "23   10/1/1995   7772.59   581.72   0.62    5.5 -0.65  84.1324   \n",
       "24    1/1/1996   7868.47   620.73   0.40    5.6 -0.68  85.2252   \n",
       "25    4/1/1996   8032.84   653.73   1.11    5.6 -0.62  86.7265   \n",
       "26    7/1/1996   8131.41   675.88   1.47    5.5 -0.66  87.6481   \n",
       "27   10/1/1996   8259.77   689.08   1.55    5.2 -0.69  87.9329   \n",
       "28    1/1/1997   8362.66   737.01   1.35    5.3 -0.62  88.7042   \n",
       "29    4/1/1997   8518.83   759.64   1.58    5.1 -0.67  93.0883   \n",
       "30    7/1/1997   8662.82   891.03   1.27    4.9 -0.68  92.6502   \n",
       "31   10/1/1997   8765.91   955.41   0.94    4.7 -0.62  94.6308   \n",
       "..         ...       ...      ...    ...    ...   ...      ...   \n",
       "86    7/1/2011  15591.85  1339.67   3.20    9.0 -0.33  69.0975   \n",
       "87   10/1/2011  15796.46  1099.23   1.78    8.8  0.12  73.3657   \n",
       "88    1/1/2012  16019.76  1277.06   1.95    8.3 -0.06  72.9043   \n",
       "89    4/1/2012  16152.26  1419.04   2.14    8.2 -0.33  72.5836   \n",
       "90    7/1/2012  16257.15  1365.51   1.51    8.2 -0.24  74.7085   \n",
       "91   10/1/2012  16358.86  1444.49   1.55    7.8 -0.45  72.7076   \n",
       "92    1/1/2013  16569.59  1462.42   1.78    8.0 -0.54  73.3738   \n",
       "93    4/1/2013  16637.93  1562.17   1.78    7.6 -0.61  76.1008   \n",
       "94    7/1/2013  16848.75  1614.96   2.46    7.3 -0.57  77.4363   \n",
       "95   10/1/2013  17083.14  1695.00   2.64    7.2 -0.63  75.2495   \n",
       "96    1/1/2014  17102.93  1831.98   2.93    6.6 -0.75   76.426   \n",
       "97    4/1/2014  17425.77  1885.52   2.73    6.2 -0.78  76.5809   \n",
       "98    7/1/2014  17719.84  1973.32   2.56    6.2 -0.81  75.6811   \n",
       "99   10/1/2014  17838.45  1946.16   2.40    5.7 -0.73  80.9928   \n",
       "100   1/1/2015  17970.42  2058.20   2.10    5.7 -0.64  85.7577   \n",
       "101   4/1/2015  18221.30  2059.69   1.84    5.4 -0.70  91.7881   \n",
       "102   7/1/2015  18331.09  2077.42   2.42    5.2 -0.70  90.4411   \n",
       "103  10/1/2015  18354.37  1923.82   2.05    5.0 -0.58  91.6013   \n",
       "104   1/1/2016  18409.13  2012.66   2.02    4.9 -0.51  94.6663   \n",
       "105   4/1/2016  18640.73  2072.78   1.56    5.0 -0.56  89.9376   \n",
       "106   7/1/2016  18799.65  2102.95   1.18    4.8 -0.53   89.892   \n",
       "107  10/1/2016  18979.24  2161.20   1.31    4.9 -0.54  90.2321   \n",
       "108   1/1/2017  19162.55  2257.83   1.92    4.7 -0.68  96.4677   \n",
       "109   4/1/2017  19359.12  2358.84   1.56    4.4 -0.69  94.2513   \n",
       "110   7/1/2017  19588.07  2429.01   1.29    4.3 -0.79  90.8407   \n",
       "111  10/1/2017  19831.83  2529.12   1.33    4.1 -0.81  88.3967   \n",
       "112   1/1/2018  20041.05  2695.81   1.02    4.1 -0.83  87.2663   \n",
       "113   4/1/2018  20411.92  2581.88   0.96    3.9 -0.73  86.4032   \n",
       "114   7/1/2018  20658.20  2726.71   0.89    3.9 -0.77  90.4184   \n",
       "115  10/1/2018  20865.14  2924.59   0.86    3.8 -0.83  90.1677   \n",
       "\n",
       "     ManufacturingConfidence  HousePriceIndex ConsumerSentiment  ...    VIX  \\\n",
       "2                      98.75           165.84              88.2  ...  16.26   \n",
       "3                      97.85           165.20              63.9  ...  28.06   \n",
       "4                      97.13           166.57              66.8  ...  27.93   \n",
       "5                      97.82           167.70              81.8  ...  17.42   \n",
       "6                      99.58           167.99              82.9  ...  18.64   \n",
       "7                      99.78           170.35              78.3  ...  14.81   \n",
       "8                      99.11           171.67              67.5  ...  18.75   \n",
       "9                     100.15           171.64              77.2  ...  16.48   \n",
       "10                    100.05           173.60              76.6  ...  13.34   \n",
       "11                     99.62           174.47              73.3  ...  16.31   \n",
       "12                    100.37           174.54              89.3  ...  13.35   \n",
       "13                     99.64           176.20              85.6  ...  13.02   \n",
       "14                     99.33           177.62                77  ...  11.51   \n",
       "15                     99.91           179.09              82.7  ...  11.83   \n",
       "16                    100.57           180.22              94.3  ...  12.57   \n",
       "17                    100.90           181.31              92.6  ...  18.13   \n",
       "18                    101.11           182.06                89  ...  14.36   \n",
       "19                    101.21           181.90              92.7  ...  15.44   \n",
       "20                    100.67           182.86              97.6  ...  13.53   \n",
       "21                     99.38           185.85              92.5  ...   13.5   \n",
       "22                     98.93           188.72              94.4  ...  11.57   \n",
       "23                     98.66           190.19              90.2  ...  13.95   \n",
       "24                     98.43           192.34              89.3  ...   12.1   \n",
       "25                     99.06           192.67              92.7  ...   17.9   \n",
       "26                     99.55           193.53              94.7  ...  13.78   \n",
       "27                     99.67           195.04              96.5  ...  17.05   \n",
       "28                    100.13           196.66              97.4  ...  19.13   \n",
       "29                    100.23           198.31             101.4  ...  20.84   \n",
       "30                    100.65           201.04             107.1  ...     21   \n",
       "31                    100.49           203.64             105.6  ...  22.32   \n",
       "..                       ...              ...               ...  ...    ...   \n",
       "86                    100.07           309.73              63.7  ...  15.87   \n",
       "87                     99.69           311.09              60.8  ...  45.45   \n",
       "88                     99.95           307.81                75  ...  22.22   \n",
       "89                    100.08           306.54              76.4  ...  15.64   \n",
       "90                     99.47           310.51              72.3  ...   16.8   \n",
       "91                     99.37           313.02              82.6  ...  16.32   \n",
       "92                     99.78           314.64              73.8  ...  14.56   \n",
       "93                     99.59           319.56              76.4  ...  13.58   \n",
       "94                    100.08           324.53              85.1  ...  16.37   \n",
       "95                    100.51           327.26              73.2  ...  15.54   \n",
       "96                    100.18           330.16              81.2  ...  13.76   \n",
       "97                    100.42           336.46              84.1  ...   13.1   \n",
       "98                    100.62           341.32              81.8  ...  11.15   \n",
       "99                    100.78           344.13              86.9  ...  16.71   \n",
       "100                   100.18           347.56              98.1  ...  19.92   \n",
       "101                    99.81           353.68              95.9  ...  15.11   \n",
       "102                    99.73           359.16              93.1  ...  16.09   \n",
       "103                    99.15           362.42                90  ...  22.55   \n",
       "104                    99.03           365.78                92  ...  19.34   \n",
       "105                    99.59           372.95                89  ...   13.1   \n",
       "106                    99.69           379.67                90  ...  14.77   \n",
       "107                    99.75           383.16              87.2  ...  13.57   \n",
       "108                   100.58           386.71              98.5  ...  11.85   \n",
       "109                   100.54           396.70                97  ...  12.38   \n",
       "110                   100.87           403.46              93.4  ...  11.22   \n",
       "111                   101.25           407.67             100.7  ...   9.45   \n",
       "112                   101.32           413.53              95.7  ...   9.15   \n",
       "113                   101.11           423.91              98.8  ...  23.62   \n",
       "114                   101.31           430.76              97.9  ...   15.6   \n",
       "115                   101.13           432.14              98.6  ...     12   \n",
       "\n",
       "     spHistoricalMax  spMaxAchieved  spBelowMax  spQuarterPerformance  \\\n",
       "2         367.399994              1   -0.104219              0.061529   \n",
       "3         368.950012              1   -0.184253             -0.124047   \n",
       "4         368.950012              0   -0.199187              0.036547   \n",
       "5         376.720001              1   -0.173153              0.137387   \n",
       "6         390.450012              1   -0.056038              0.017829   \n",
       "7         396.640015              1   -0.058769              0.029848   \n",
       "8         417.260010              1   -0.100753              0.072097   \n",
       "9         420.769989              1   -0.042232             -0.031228   \n",
       "10        420.769989              0   -0.062433              0.021399   \n",
       "11        425.269989              1   -0.037882              0.008259   \n",
       "12        441.279999              1   -0.087518              0.045857   \n",
       "13        456.329987              1   -0.059781              0.034269   \n",
       "14        456.329987              0   -0.049942             -0.002843   \n",
       "15        463.559998              1   -0.047739              0.027304   \n",
       "16        470.940002              1   -0.028560              0.009018   \n",
       "17        482.000000              1   -0.075622             -0.056978   \n",
       "18        482.000000              0   -0.089378              0.016586   \n",
       "19        482.000000              0   -0.074419              0.034827   \n",
       "20        482.000000              0   -0.075830             -0.005696   \n",
       "21        503.899994              1   -0.088887              0.093093   \n",
       "22        551.070007              1   -0.089317              0.090146   \n",
       "23        586.770020              1   -0.067624              0.063298   \n",
       "24        621.690002              1   -0.072335              0.067060   \n",
       "25        661.450012              1   -0.095200              0.053163   \n",
       "26        678.510010              1   -0.069756              0.033883   \n",
       "27        689.080017              1   -0.090599              0.019530   \n",
       "28        757.030029              1   -0.089759              0.069556   \n",
       "29        816.289978              1   -0.097122              0.030705   \n",
       "30        898.700012              1   -0.179203              0.172964   \n",
       "31        960.320007              1   -0.072153              0.072253   \n",
       "..               ...            ...         ...                   ...   \n",
       "86       1565.150024              0   -0.191502              0.005449   \n",
       "87       1565.150024              0   -0.284759             -0.179477   \n",
       "88       1565.150024              0   -0.297684              0.161777   \n",
       "89       1565.150024              0   -0.184065              0.111177   \n",
       "90       1565.150024              0   -0.183439             -0.037723   \n",
       "91       1565.150024              0   -0.147200              0.057839   \n",
       "92       1565.150024              0   -0.135335              0.012413   \n",
       "93       1569.189941              1   -0.071400              0.068209   \n",
       "94       1669.160034              1   -0.076416              0.033793   \n",
       "95       1725.520020              1   -0.064583              0.049562   \n",
       "96       1848.359985              1   -0.104368              0.080814   \n",
       "97       1885.520020              1   -0.076175              0.029225   \n",
       "98       1973.319946              1   -0.079881              0.046565   \n",
       "99       2011.359985              1   -0.050608             -0.013764   \n",
       "100      2090.570068              1   -0.109099              0.057570   \n",
       "101      2117.389893              1   -0.058903              0.000724   \n",
       "102      2130.820068              1   -0.034344              0.008608   \n",
       "103      2130.820068              0   -0.123525             -0.073938   \n",
       "104      2130.820068              0   -0.097146              0.046179   \n",
       "105      2130.820068              0   -0.141608              0.029871   \n",
       "106      2130.820068              0   -0.061141              0.014555   \n",
       "107      2190.149902              1   -0.046389              0.027699   \n",
       "108      2271.719971              1   -0.082114              0.044711   \n",
       "109      2395.959961              1   -0.057651              0.044738   \n",
       "110      2453.459961              1   -0.050749              0.029748   \n",
       "111      2529.120117              1   -0.047198              0.041214   \n",
       "112      2695.810059              1   -0.061833              0.065908   \n",
       "113      2872.870117              1   -0.101595             -0.042262   \n",
       "114      2872.870117              0   -0.101289              0.056095   \n",
       "115      2930.750000              1   -0.074223              0.072571   \n",
       "\n",
       "      QuarterMax   QuarterMin  spMaxQuarterDrawdown  spMove  gdpGrowth  \n",
       "2     367.399994   329.109985             -0.045339       1        0.6  \n",
       "3     368.950012   300.970001             -0.184253       0       -1.0  \n",
       "4     331.750000   295.459991             -0.062657       1       -0.5  \n",
       "5     376.720001   311.489990             -0.045826       1       -0.1  \n",
       "6     390.450012   368.570007             -0.056038       1        1.2  \n",
       "7     396.640015   373.329987             -0.012145       1        2.9  \n",
       "8     417.089996   375.220001             -0.055837       1        3.2  \n",
       "9     420.769989   403.000000             -0.042232       0        3.7  \n",
       "10    418.489990   394.500000             -0.027343       1        4.4  \n",
       "11    425.269989   409.160004             -0.011309       1        3.3  \n",
       "12    441.279999   402.660004             -0.032742       1        2.8  \n",
       "13    456.329987   429.049988             -0.014539       1        2.3  \n",
       "14    453.850006   433.540009             -0.037220       0        2.6  \n",
       "15    463.559998   441.429993             -0.016903       1        3.4  \n",
       "16    470.940002   457.489990             -0.025580       1        4.2  \n",
       "17    482.000000   445.549988             -0.075622       0        4.3  \n",
       "18    462.369995   438.920013            438.920013       1        4.1  \n",
       "19    476.070007   446.130005             -0.000538       1        3.5  \n",
       "20    473.769989   445.450012             -0.059776       0        2.4  \n",
       "21    503.899994   459.109985            459.109985       1        2.7  \n",
       "22    551.070007   501.850006            501.850006       1        2.2  \n",
       "23    586.770020   547.090027            547.090027       1        2.6  \n",
       "24    621.690002   576.719971             -0.023584       1        4.0  \n",
       "25    661.450012   598.479980             -0.036760       1        4.1  \n",
       "26    678.510010   631.179993             -0.037659       1        4.4  \n",
       "27    687.330017   626.650024             -0.072838       1        4.3  \n",
       "28    757.030029   689.080017            689.080017       1        4.3  \n",
       "29    816.289978   737.010010            737.010010       1        4.7  \n",
       "30    898.700012   737.650024             -0.037161       1        4.5  \n",
       "31    960.320007   891.030029            891.030029       1        4.9  \n",
       "..           ...          ...                   ...     ...        ...  \n",
       "86   1363.609985  1265.420044             -0.072007       1        1.6  \n",
       "87   1353.219971  1119.459961             -0.172744       0        2.7  \n",
       "88   1285.089966  1099.229980           1099.229980       1        2.4  \n",
       "89   1416.510010  1277.060059           1277.060059       1        2.5  \n",
       "90   1419.040039  1278.040039             -0.099363       0        1.5  \n",
       "91   1465.770020  1334.760010             -0.028573       1        1.6  \n",
       "92   1461.400024  1353.329956             -0.073950       1        1.3  \n",
       "93   1569.189941  1457.150024             -0.006355       1        1.9  \n",
       "94   1669.160034  1541.609985             -0.032485       1        2.6  \n",
       "95   1725.520020  1614.079956             -0.000545       1        1.5  \n",
       "96   1848.359985  1655.449951             -0.023333       1        2.6  \n",
       "97   1878.040039  1741.890015             -0.057613       1        3.0  \n",
       "98   1962.869995  1815.689941             -0.039775       1        2.7  \n",
       "99   2011.359985  1909.569946             -0.039442       0        3.8  \n",
       "100  2090.570068  1862.489990             -0.054041       1        3.4  \n",
       "101  2117.389893  1992.670044             -0.033688       1        2.4  \n",
       "102  2130.820068  2057.639893             -0.034344       1        2.0  \n",
       "103  2128.280029  1867.609985             -0.122479       0        1.6  \n",
       "104  2109.790039  1923.819946           1923.819946       1        1.3  \n",
       "105  2063.949951  1829.079956             -0.093038       1        1.5  \n",
       "106  2119.120117  2000.540039             -0.055957       1        1.9  \n",
       "107  2190.149902  2088.550049             -0.006847       1        1.9  \n",
       "108  2271.719971  2085.179932             -0.036272       1        2.1  \n",
       "109  2395.959961  2257.830078           2257.830078       1        2.3  \n",
       "110  2453.459961  2328.949951             -0.013224       1        2.5  \n",
       "111  2519.360107  2409.750000             -0.009369       1        2.6  \n",
       "112  2690.159912  2529.120117           2529.120117       1        2.9  \n",
       "113  2872.870117  2581.000000             -0.101595       0        3.0  \n",
       "114  2786.850098  2581.879883           2581.879883       1        3.0  \n",
       "115  2930.750000  2713.219971             -0.004947       1        3.0  \n",
       "\n",
       "[114 rows x 26 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bear markets in this dataset\n",
    "# March 2000 to October 2002 [41:52] \n",
    "# October 2007 to March 2009 [71:77]\n",
    "\n",
    "# Recessions in this dataset\n",
    "\n",
    "bearMarket = []\n",
    "recession = []\n",
    "\n",
    "for i in range(0, len(finalData)):\n",
    "    if (39 <= i <= 50) or (70 <= i <= 75):\n",
    "        bearMarket.append(1)\n",
    "    else:\n",
    "        bearMarket.append(0)\n",
    "finalData['bearMarket'] = bearMarket\n",
    "\n",
    "for i in range(0, len(finalData)):\n",
    "    if (0 <= i <= 2) or (42 <= i <= 44) or (69 <= i <= 75):\n",
    "        recession.append(1)\n",
    "    else:\n",
    "        recession.append(0)\n",
    "finalData['recession'] = recession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregatedData = finalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearMarket = finalData[finalData['bearMarket'] == 1]\n",
    "bullMarket = finalData[finalData['bearMarket'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above work was data preparation, cleaning, and alignment, to allow for machine learning algorithms to properly work on the data at hand. The reason this had to be done was to match all the different data points on a quarterly basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Principal Compoment Analysis with Cleaned Aligned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below implemenation of principal component analysis is used to find the most relevant data points in our model using \n",
    "# dimensionality reduction, which is the process of reducing the number of random variables under consideration, by \n",
    "# obtaining a set of principal variables. This occurs by finding the eigenvectors and eigenvalues of the calculated \n",
    "# covariance matrix to identify the principal components. Principal components show the mamixmum amount of variance, \n",
    "# to capture the most possible information out of each data point possible. Therefore, the greater the variance, the \n",
    "# greater the amount of information contained within the data. Each principal component must be uncorrelated to the one \n",
    "# prior to it. Eigenvectors are relevant in this case as eigenvectors of the covariance matrix are actually the directions \n",
    "# of the axes where there is the most variance. And eigenvalues are simply the coefficients attached to eigenvectors, \n",
    "# which give the amount of variance carried in each Principal Component, from which we can determine the amount of \n",
    "# variance that is explained by each value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepColumns = ['T10T3', 'uRate', 'nfci', 'USDIndex',\n",
    "       'ManufacturingConfidence', 'HousePriceIndex', 'ConsumerSentiment',\n",
    "       'PeopleOutputPerHour', 'GS10', 'FEDFUNDS', 'USNIM', 'govtToGDP',\n",
    "       'CorporateProfits', 'VIX']\n",
    "dates = finalData['Date']\n",
    "GrossDomesticProduct = finalData['GDP']\n",
    "StandardandPoors = finalData['SP500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# PCA overview\n",
    "\n",
    "bearMarket = bearMarket[keepColumns]\n",
    "bullMarket = bullMarket[keepColumns]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pcaTestbearMarket = StandardScaler().fit_transform(bearMarket)\n",
    "pcaTestbullMarket = StandardScaler().fit_transform(bullMarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05882353  0.69768887  0.22768189 -0.07932444  0.02954967  0.37046228\n",
      "  -0.54450791  0.43737624 -0.50782936 -0.94912303 -0.04537989  0.51114098\n",
      "   0.14377941  0.23908947]\n",
      " [ 0.69768887  1.05882353  0.75855438 -0.41929593 -0.51984422  0.63673953\n",
      "  -0.76045609  0.69211575 -0.86951742 -0.92815034 -0.49292726  0.89836907\n",
      "   0.45974232  0.74584498]\n",
      " [ 0.22768189  0.75855438  1.05882353 -0.80748262 -0.76570516  0.81682564\n",
      "  -0.82911497  0.7943465  -0.82254368 -0.55884893 -0.90120474  0.89928776\n",
      "   0.63640437  0.75656443]\n",
      " [-0.07932444 -0.41929593 -0.80748262  1.05882353  0.30210455 -0.97032248\n",
      "   0.80520708 -0.95199367  0.72440969  0.35690266  0.96935226 -0.80962035\n",
      "  -0.95118899 -0.33067203]\n",
      " [ 0.02954967 -0.51984422 -0.76570516  0.30210455  1.05882353 -0.38154787\n",
      "   0.56277545 -0.3112526   0.57820023  0.30034304  0.60117595 -0.53241567\n",
      "  -0.15704261 -0.78333421]\n",
      " [ 0.37046228  0.63673953  0.81682564 -0.97032248 -0.38154787  1.05882353\n",
      "  -0.94597302  1.04858661 -0.90531335 -0.63576439 -0.93912953  0.93759291\n",
      "   0.9596426   0.41158702]\n",
      " [-0.54450791 -0.76045609 -0.82911497  0.80520708  0.56277545 -0.94597302\n",
      "   1.05882353 -0.94172321  0.96545725  0.81742652  0.85017907 -0.96118983\n",
      "  -0.7618609  -0.64485173]\n",
      " [ 0.43737624  0.69211575  0.7943465  -0.95199367 -0.3112526   1.04858661\n",
      "  -0.94172321  1.05882353 -0.91967864 -0.6935149  -0.89771519  0.9574127\n",
      "   0.96076699  0.42407772]\n",
      " [-0.50782936 -0.86951742 -0.82254368  0.72440969  0.57820023 -0.90531335\n",
      "   0.96545725 -0.91967864  1.05882353  0.84883611  0.76229017 -0.96971628\n",
      "  -0.77263883 -0.70977681]\n",
      " [-0.94912303 -0.92815034 -0.55884893  0.35690266  0.30034304 -0.63576439\n",
      "   0.81742652 -0.6935149   0.84883611  1.05882353  0.37014633 -0.80705943\n",
      "  -0.4133224  -0.56348998]\n",
      " [-0.04537989 -0.49292726 -0.90120474  0.96935226  0.60117595 -0.93912953\n",
      "   0.85017907 -0.89771519  0.76229017  0.37014633  1.05882353 -0.84724689\n",
      "  -0.84390555 -0.47335164]\n",
      " [ 0.51114098  0.89836907  0.89928776 -0.80962035 -0.53241567  0.93759291\n",
      "  -0.96118983  0.9574127  -0.96971628 -0.80705943 -0.84724689  1.05882353\n",
      "   0.83068603  0.63932351]\n",
      " [ 0.14377941  0.45974232  0.63640437 -0.95118899 -0.15704261  0.9596426\n",
      "  -0.7618609   0.96076699 -0.77263883 -0.4133224  -0.84390555  0.83068603\n",
      "   1.05882353  0.20127593]\n",
      " [ 0.23908947  0.74584498  0.75656443 -0.33067203 -0.78333421  0.41158702\n",
      "  -0.64485173  0.42407772 -0.70977681 -0.56348998 -0.47335164  0.63932351\n",
      "   0.20127593  1.05882353]]\n",
      "[[ 1.01052632  0.69853505  0.07701569 -0.28183065  0.31670523 -0.1545143\n",
      "  -0.46065555  0.01859534 -0.06567024 -0.55221037  0.13207131  0.61696312\n",
      "  -0.05099668  0.01166102]\n",
      " [ 0.69853505  1.01052632  0.4811713  -0.6812171  -0.02873958 -0.14787444\n",
      "  -0.81712956  0.11365159 -0.1272522  -0.45011823  0.09112244  0.88074074\n",
      "   0.05127556  0.20616756]\n",
      " [ 0.07701569  0.4811713   1.01052632 -0.28475046 -0.39337327 -0.10671158\n",
      "  -0.5128516   0.0318978   0.0427289   0.01273942 -0.01395908  0.36549413\n",
      "  -0.05838368  0.68534649]\n",
      " [-0.28183065 -0.6812171  -0.28475046  1.01052632 -0.08078848 -0.3139511\n",
      "   0.71830014 -0.48803686  0.36803851  0.44614112  0.33036401 -0.66196302\n",
      "  -0.47863425  0.07347019]\n",
      " [ 0.31670523 -0.02873958 -0.39337327 -0.08078848  1.01052632  0.3738751\n",
      "   0.25165431  0.36541951 -0.27600902 -0.40398407 -0.16090759 -0.0117603\n",
      "   0.31777539 -0.23508225]\n",
      " [-0.1545143  -0.14787444 -0.10671158 -0.3139511   0.3738751   1.01052632\n",
      "  -0.02198774  0.94522772 -0.83421932 -0.6291009  -0.91314607  0.0833474\n",
      "   0.93804029 -0.19155186]\n",
      " [-0.46065555 -0.81712956 -0.5128516   0.71830014  0.25165431 -0.02198774\n",
      "   1.01052632 -0.17655123  0.13760428  0.3412475   0.08732974 -0.78978443\n",
      "  -0.16621842 -0.15476317]\n",
      " [ 0.01859534  0.11365159  0.0318978  -0.48803686  0.36541951  0.94522772\n",
      "  -0.17655123  1.01052632 -0.93509882 -0.79222696 -0.92307745  0.27279176\n",
      "   0.9786426  -0.06272675]\n",
      " [-0.06567024 -0.1272522   0.0427289   0.36803851 -0.27600902 -0.83421932\n",
      "   0.13760428 -0.93509882  1.01052632  0.87594529  0.85801109 -0.28538546\n",
      "  -0.92022707  0.03552648]\n",
      " [-0.55221037 -0.45011823  0.01273942  0.44614112 -0.40398407 -0.6291009\n",
      "   0.3412475  -0.79222696  0.87594529  1.01052632  0.65220264 -0.54665173\n",
      "  -0.74706172  0.03477606]\n",
      " [ 0.13207131  0.09112244 -0.01395908  0.33036401 -0.16090759 -0.91314607\n",
      "   0.08732974 -0.92307745  0.85801109  0.65220264  1.01052632 -0.11603292\n",
      "  -0.93417428  0.1109327 ]\n",
      " [ 0.61696312  0.88074074  0.36549413 -0.66196302 -0.0117603   0.0833474\n",
      "  -0.78978443  0.27279176 -0.28538546 -0.54665173 -0.11603292  1.01052632\n",
      "   0.27581438  0.03946212]\n",
      " [-0.05099668  0.05127556 -0.05838368 -0.47863425  0.31777539  0.93804029\n",
      "  -0.16621842  0.9786426  -0.92022707 -0.74706172 -0.93417428  0.27581438\n",
      "   1.01052632 -0.17000471]\n",
      " [ 0.01166102  0.20616756  0.68534649  0.07347019 -0.23508225 -0.19155186\n",
      "  -0.15476317 -0.06272675  0.03552648  0.03477606  0.1109327   0.03946212\n",
      "  -0.17000471  1.01052632]]\n"
     ]
    }
   ],
   "source": [
    "# OR we can do this with one line of numpy:\n",
    "import numpy as np\n",
    "cov_matbearMarket = np.cov(pcaTestbearMarket.T)\n",
    "\n",
    "print(cov_matbearMarket)\n",
    "\n",
    "cov_matbullMarket = np.cov(pcaTestbullMarket.T)\n",
    "\n",
    "print(cov_matbullMarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the eigen values and vectors using numpy\n",
    "eig_vals_bearMarket, eig_vecs_bearMarket = np.linalg.eig(cov_matbearMarket)\n",
    "\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs_bearMarket = [(np.abs(eig_vals_bearMarket[i]), eig_vecs_bearMarket[:,i]) for i in range(len(eig_vals_bearMarket))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs_bearMarket.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "##############################################################################################################################\n",
    "\n",
    "eig_vals_bullMarket, eig_vecs_bullMarket = np.linalg.eig(cov_matbullMarket)\n",
    "\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs_bullMarket = [(np.abs(eig_vals_bullMarket[i]), eig_vecs_bullMarket[:,i]) for i in range(len(eig_vals_bullMarket))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs_bullMarket.sort(key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.147368421052633"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valSum_bullMarket = 0\n",
    "\n",
    "for i in range(0, len(eig_vals_bullMarket)):\n",
    "    valSum_bullMarket += eig_vals_bullMarket[i]\n",
    "valSum_bullMarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T10T3 : 0.42538101274934165\n",
      "0.42538101274934165\n",
      "uRate : 0.2684307248788796\n",
      "0.6938117376282212\n",
      "nfci : 0.12782853208788011\n",
      "0.8216402697161014\n",
      "USDIndex : 0.07566128941292843\n",
      "0.8973015591290299\n",
      "ManufacturingConfidence : 0.04070516222500826\n",
      "0.9380067213540382\n",
      "HousePriceIndex : 0.018857821123381344\n",
      "0.9568645424774195\n",
      "ConsumerSentiment : 0.014968138735846542\n",
      "0.971832681213266\n",
      "PeopleOutputPerHour : 0.012136748459461449\n",
      "0.9839694296727275\n",
      "GS10 : 0.006940353592395664\n",
      "0.9909097832651231\n",
      "FEDFUNDS : 0.00019739301805502438\n",
      "0.9911071762831781\n",
      "USNIM : 0.0004976084793488081\n",
      "0.9916047847625269\n",
      "govtToGDP : 0.001544380785334488\n",
      "0.9931491655478614\n",
      "CorporateProfits : 0.003855396957483967\n",
      "0.9970045625053453\n",
      "VIX : 0.0029954374946548116\n",
      "1.0000000000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['T10T3', 'uRate', 'nfci', 'USDIndex', 'ManufacturingConfidence']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Principal component regression. Bull market\n",
    "\n",
    "cumulativeVariance = 0\n",
    "keepFeatures = []\n",
    "\n",
    "for i in range(0, len(eig_vals_bullMarket)):\n",
    "    print(bullMarket.columns[i], \":\", eig_vals_bullMarket[i] / valSum_bullMarket)\n",
    "    cumulativeVariance = cumulativeVariance + (eig_vals_bullMarket[i] / valSum_bullMarket)\n",
    "    print(cumulativeVariance)\n",
    "    if cumulativeVariance < .95:\n",
    "        keepFeatures.append(bullMarket.columns[i])\n",
    "keepFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tells us in a bull market, the 10 Year to 3 Month Treasury spread, unemployment, the net financial conditions index, the USD Index, and manufacturing confidence explain around 95% of the variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.823529411764722"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valSum_bearMarket = 0\n",
    "\n",
    "for i in range(0, len(eig_vals_bearMarket)):\n",
    "    valSum_bearMarket += eig_vals_bearMarket[i]\n",
    "valSum_bearMarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T10T3 : 0.6764886000655195\n",
      "0.6764886000655195\n",
      "uRate : 0.14587588064102483\n",
      "0.8223644807065443\n",
      "nfci : 0.11318523361678383\n",
      "0.9355497143233281\n",
      "USDIndex : 0.020841481077244407\n",
      "0.9563911954005725\n",
      "ManufacturingConfidence : 0.016441855538251605\n",
      "0.9728330509388241\n",
      "HousePriceIndex : 0.014202927955721582\n",
      "0.9870359788945456\n",
      "ConsumerSentiment : 0.004636577337778211\n",
      "0.9916725562323239\n",
      "PeopleOutputPerHour : 0.003248823787082391\n",
      "0.9949213800194062\n",
      "GS10 : 0.0021174148713693753\n",
      "0.9970387948907756\n",
      "FEDFUNDS : 0.0013830061987347676\n",
      "0.9984218010895104\n",
      "USNIM : 0.0009058748192862953\n",
      "0.9993276759087967\n",
      "govtToGDP : 0.0005538114089430306\n",
      "0.9998814873177397\n",
      "CorporateProfits : 7.976701635998578e-05\n",
      "0.9999612543340998\n",
      "VIX : 3.874566590016237e-05\n",
      "0.9999999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['T10T3', 'uRate', 'nfci']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Principal component regression. Bear market\n",
    "\n",
    "cumulativeVariance = 0\n",
    "keepFeatures = []\n",
    "\n",
    "for i in range(0, len(eig_vals_bearMarket)):\n",
    "    print(bearMarket.columns[i], \":\", eig_vals_bearMarket[i] / valSum_bearMarket)\n",
    "    cumulativeVariance = cumulativeVariance + (eig_vals_bearMarket[i] / valSum_bearMarket)\n",
    "    print(cumulativeVariance)\n",
    "    if cumulativeVariance < .95:\n",
    "        keepFeatures.append(bearMarket.columns[i])\n",
    "keepFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tells us in a bear market, the 10 Year to 3 Month Treasury spread, unemployment, the net financial conditions indexexplain around 95% of the variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "finalDataPCA = finalData[keepColumns]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pcaTestfinalDataPCA = StandardScaler().fit_transform(finalDataPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00884956  0.68076192  0.0907866  -0.20768068  0.23023965 -0.09207856\n",
      "  -0.46730652  0.05524655 -0.10435044 -0.60700722  0.10622832  0.57897957\n",
      "  -0.0247804   0.04016726]\n",
      " [ 0.68076192  1.00884956  0.32442141 -0.58396471 -0.03162163 -0.08883385\n",
      "  -0.75614042  0.14721712 -0.17293722 -0.50017185  0.04092456  0.86964335\n",
      "   0.1046452   0.17912888]\n",
      " [ 0.0907866   0.32442141  1.00884956 -0.20501119 -0.62304585  0.07695894\n",
      "  -0.56022306  0.11345595 -0.08512657 -0.10236316 -0.1653275   0.29503586\n",
      "  -0.08218558  0.73762597]\n",
      " [-0.20768068 -0.58396471 -0.20501119  1.00884956 -0.1395028  -0.34178555\n",
      "   0.62535969 -0.45052585  0.34291653  0.38104442  0.37328424 -0.69422625\n",
      "  -0.51801252  0.14497254]\n",
      " [ 0.23023965 -0.03162163 -0.62304585 -0.1395028   1.00884956  0.22999029\n",
      "   0.34181941  0.24945746 -0.15516216 -0.25683754 -0.04438355 -0.00443198\n",
      "   0.32943528 -0.49830298]\n",
      " [-0.09207856 -0.08883385  0.07695894 -0.34178555  0.22999029  1.00884956\n",
      "  -0.13000949  0.9451989  -0.83377719 -0.62033291 -0.90995065  0.15917983\n",
      "   0.90298543 -0.09594262]\n",
      " [-0.46730652 -0.75614042 -0.56022306  0.62535969  0.34181941 -0.13000949\n",
      "   1.00884956 -0.23737475  0.21228189  0.40920442  0.18497623 -0.76342922\n",
      "  -0.1771486  -0.28661819]\n",
      " [ 0.05524655  0.14721712  0.11345595 -0.45052585  0.24945746  0.9451989\n",
      "  -0.23737475  1.00884956 -0.93111196 -0.77046169 -0.91513493  0.31216131\n",
      "   0.94742556 -0.01599085]\n",
      " [-0.10435044 -0.17293722 -0.08512657  0.34291653 -0.15516216 -0.83377719\n",
      "   0.21228189 -0.93111196  1.00884956  0.85861131  0.84723822 -0.32691534\n",
      "  -0.88476272 -0.03094769]\n",
      " [-0.60700722 -0.50017185 -0.10236316  0.38104442 -0.25683754 -0.62033291\n",
      "   0.40920442 -0.77046169  0.85861131  1.00884956  0.61873563 -0.5707133\n",
      "  -0.69657128 -0.03848442]\n",
      " [ 0.10622832  0.04092456 -0.1653275   0.37328424 -0.04438355 -0.90995065\n",
      "   0.18497623 -0.91513493  0.84723822  0.61873563  1.00884956 -0.19112883\n",
      "  -0.89420705  0.02779981]\n",
      " [ 0.57897957  0.86964335  0.29503586 -0.69422625 -0.00443198  0.15917983\n",
      "  -0.76342922  0.31216131 -0.32691534 -0.5707133  -0.19112883  1.00884956\n",
      "   0.34741576  0.02677733]\n",
      " [-0.0247804   0.1046452  -0.08218558 -0.51801252  0.32943528  0.90298543\n",
      "  -0.1771486   0.94742556 -0.88476272 -0.69657128 -0.89420705  0.34741576\n",
      "   1.00884956 -0.22603746]\n",
      " [ 0.04016726  0.17912888  0.73762597  0.14497254 -0.49830298 -0.09594262\n",
      "  -0.28661819 -0.01599085 -0.03094769 -0.03848442  0.02779981  0.02677733\n",
      "  -0.22603746  1.00884956]]\n"
     ]
    }
   ],
   "source": [
    "# OR we can do this with one line of numpy:\n",
    "import numpy as np\n",
    "cov_mat_allData = np.cov(pcaTestfinalDataPCA.T)\n",
    "\n",
    "print(cov_mat_allData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_allData, eig_vecs_allData = np.linalg.eig(cov_mat_allData)\n",
    "\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs_allData = [(np.abs(eig_vals_allData[i]), eig_vecs_allData[:,i]) for i in range(len(eig_vals_allData))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs_allData.sort(key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.123893805309724"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valSum_allData = 0\n",
    "\n",
    "for i in range(0, len(eig_vals_allData)):\n",
    "    valSum_allData += eig_vals_allData[i]\n",
    "valSum_allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T10T3 : 0.42755808650771826\n",
      "0.42755808650771826\n",
      "uRate : 0.24453368073027412\n",
      "0.6720917672379924\n",
      "nfci : 0.15396052422110315\n",
      "0.8260522914590955\n",
      "USDIndex : 0.07489509084574118\n",
      "0.9009473823048367\n",
      "ManufacturingConfidence : 0.033685235229177164\n",
      "0.9346326175340139\n",
      "HousePriceIndex : 0.02197591637985096\n",
      "0.9566085339138649\n",
      "ConsumerSentiment : 0.012656023324236926\n",
      "0.9692645572381018\n",
      "PeopleOutputPerHour : 0.011174543980093753\n",
      "0.9804391012181956\n",
      "GS10 : 0.00022754754690922492\n",
      "0.9806666487651048\n",
      "FEDFUNDS : 0.0008397752853348407\n",
      "0.9815064240504396\n",
      "USNIM : 0.001640589632957301\n",
      "0.983147013683397\n",
      "govtToGDP : 0.0036748385477954107\n",
      "0.9868218522311923\n",
      "CorporateProfits : 0.0070612208658196425\n",
      "0.993883073097012\n",
      "VIX : 0.006116926902987989\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['T10T3', 'uRate', 'nfci', 'USDIndex', 'ManufacturingConfidence']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulativeVariance = 0\n",
    "keepFeatures = []\n",
    "\n",
    "for i in range(0, len(eig_vals_allData)):\n",
    "    print(finalDataPCA.columns[i], \":\", eig_vals_allData[i] / valSum_allData)\n",
    "    cumulativeVariance = cumulativeVariance + (eig_vals_allData[i] / valSum_allData)\n",
    "    print(cumulativeVariance)\n",
    "    if cumulativeVariance < .95:\n",
    "        keepFeatures.append(finalDataPCA.columns[i])\n",
    "keepFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tells us in all market data that has been collected, the 10 Year to 3 Month Treasury spread, unemployment, the net financial conditions index, the USD Index, and manufacturing confidence explain around 95% of the variance in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multi-layer perceptron algorithm like the one used above is made up of many individual nuerons, which are simple \n",
    "# computational units that have weighted input signals and produce an output signal using an activation function. These \n",
    "# activation functions can have a threshold, especially with a binary classifier, that decides whether 0 or 1 is output.\n",
    "# In this case, data flows through an input layer, a hidden layer, and an output layer to predict whether there is a \n",
    "# recession or not. In this case, input is a feature vector x multiplied by weights w and added to a bias b: y = w * x + b.\n",
    "\n",
    "# Furthermore, the model operates by incorporating backpropagation, where the weights on each nuerons so as to minimize the \n",
    "# difference between actual output and desired output. This is where it is crucial to split this into train and test data\n",
    "# as well, so we can teach the model the characteristics of a recession. \n",
    "\n",
    "# In this case, given the inputs we have, based on our prior models we can accurately predict a recession or market downturn\n",
    "# in ~95% of cases, using a variety of different implementations.\n",
    "\n",
    "# The output seen below is known as a confidence matrix, which tells us how often we classified data properly, in this case \n",
    "# regarding bear markets. a is a bull market properly classified as a bull market, b is a bear market incorrrectly \n",
    "# classified as a bull market, c is a bull market incorrrectly classified as a bear market, and d is a bear market \n",
    "# properly classified as a bear market.  \n",
    "\n",
    "# [[a  b]\n",
    "# [c  d]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fed Data\n",
    "# https://www.kansascityfed.org/~/media/files/publicat/reswkpap/pdf/rwp17-11.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnColumns = ['GDP', 'SP500', 'T10T3', 'uRate', 'nfci', 'USDIndex',\n",
    "       'ManufacturingConfidence', 'HousePriceIndex', 'ConsumerSentiment',\n",
    "       'PeopleOutputPerHour', 'GS10', 'FEDFUNDS', 'USNIM', 'govtToGDP',\n",
    "       'CorporateProfits', 'VIX', 'gdpGrowth', 'bearMarket'] \n",
    "\n",
    "nnData = finalData[nnColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  1]\n",
      " [ 1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        23\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        29\n",
      "   macro avg       0.89      0.89      0.89        29\n",
      "weighted avg       0.93      0.93      0.93        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(nnData.drop('bearMarket', axis=1), nnData['bearMarket'], test_size = 0.25)\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "mlp = MLPClassifier(max_iter=100)          \n",
    "parameter_space = {'hidden_layer_sizes': [(50,50,50), (100,100,100), (150,150,150)], 'activation': ['tanh', 'relu'],\n",
    "'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive'],}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "predictions = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN model with most predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnColumns = ['T10T3', 'uRate', 'nfci', 'USDIndex', 'ManufacturingConfidence', 'bearMarket'] \n",
    "\n",
    "nnData = finalData[nnColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  3]\n",
      " [ 1  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        35\n",
      "           1       0.40      0.67      0.50         3\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        38\n",
      "   macro avg       0.68      0.79      0.72        38\n",
      "weighted avg       0.92      0.89      0.91        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(nnData.drop('bearMarket', axis=1), nnData['bearMarket'], test_size = 0.33)\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "mlp = MLPClassifier(max_iter=100)          \n",
    "parameter_space = {'hidden_layer_sizes': [(150,150,150), (200,200,200), (250,250,250)], 'activation': ['tanh', 'relu'],\n",
    "'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive'],}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "predictions = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>T10T3</th>\n",
       "      <th>uRate</th>\n",
       "      <th>nfci</th>\n",
       "      <th>USDIndex</th>\n",
       "      <th>ManufacturingConfidence</th>\n",
       "      <th>HousePriceIndex</th>\n",
       "      <th>ConsumerSentiment</th>\n",
       "      <th>PeopleOutputPerHour</th>\n",
       "      <th>GS10</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>USNIM</th>\n",
       "      <th>govtToGDP</th>\n",
       "      <th>CorporateProfits</th>\n",
       "      <th>VIX</th>\n",
       "      <th>gdpGrowth</th>\n",
       "      <th>bearMarket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/1/1990</td>\n",
       "      <td>6015.12</td>\n",
       "      <td>359.54</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>91.5346</td>\n",
       "      <td>98.75</td>\n",
       "      <td>165.84</td>\n",
       "      <td>88.2</td>\n",
       "      <td>48.200</td>\n",
       "      <td>8.47</td>\n",
       "      <td>8.15</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.326782</td>\n",
       "      <td>413.339</td>\n",
       "      <td>16.26</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1990</td>\n",
       "      <td>6004.73</td>\n",
       "      <td>314.94</td>\n",
       "      <td>1.34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>86.2694</td>\n",
       "      <td>97.85</td>\n",
       "      <td>165.20</td>\n",
       "      <td>63.9</td>\n",
       "      <td>48.054</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.11</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.334054</td>\n",
       "      <td>413.234</td>\n",
       "      <td>28.06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/1991</td>\n",
       "      <td>6035.18</td>\n",
       "      <td>326.45</td>\n",
       "      <td>1.31</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>84.878</td>\n",
       "      <td>97.13</td>\n",
       "      <td>166.57</td>\n",
       "      <td>66.8</td>\n",
       "      <td>47.927</td>\n",
       "      <td>8.09</td>\n",
       "      <td>6.91</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.327388</td>\n",
       "      <td>423.450</td>\n",
       "      <td>27.93</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/1/1991</td>\n",
       "      <td>6126.86</td>\n",
       "      <td>371.30</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>90.2577</td>\n",
       "      <td>97.82</td>\n",
       "      <td>167.70</td>\n",
       "      <td>81.8</td>\n",
       "      <td>48.449</td>\n",
       "      <td>8.04</td>\n",
       "      <td>5.91</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.335431</td>\n",
       "      <td>425.449</td>\n",
       "      <td>17.42</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/1/1991</td>\n",
       "      <td>6205.94</td>\n",
       "      <td>377.92</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>92.8816</td>\n",
       "      <td>99.58</td>\n",
       "      <td>167.99</td>\n",
       "      <td>82.9</td>\n",
       "      <td>49.311</td>\n",
       "      <td>8.27</td>\n",
       "      <td>5.82</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.339073</td>\n",
       "      <td>431.732</td>\n",
       "      <td>18.64</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      GDP   SP500  T10T3  uRate  nfci USDIndex  \\\n",
       "2   7/1/1990  6015.12  359.54   0.43    5.5 -0.23  91.5346   \n",
       "3  10/1/1990  6004.73  314.94   1.34    5.9  0.25  86.2694   \n",
       "4   1/1/1991  6035.18  326.45   1.31    6.4  0.37   84.878   \n",
       "5   4/1/1991  6126.86  371.30   2.13    6.7 -0.20  90.2577   \n",
       "6   7/1/1991  6205.94  377.92   2.50    6.8 -0.36  92.8816   \n",
       "\n",
       "   ManufacturingConfidence  HousePriceIndex ConsumerSentiment  \\\n",
       "2                    98.75           165.84              88.2   \n",
       "3                    97.85           165.20              63.9   \n",
       "4                    97.13           166.57              66.8   \n",
       "5                    97.82           167.70              81.8   \n",
       "6                    99.58           167.99              82.9   \n",
       "\n",
       "   PeopleOutputPerHour  GS10  FEDFUNDS  USNIM  govtToGDP  CorporateProfits  \\\n",
       "2               48.200  8.47      8.15   4.00   0.326782           413.339   \n",
       "3               48.054  8.72      8.11   4.03   0.334054           413.234   \n",
       "4               47.927  8.09      6.91   4.08   0.327388           423.450   \n",
       "5               48.449  8.04      5.91   4.11   0.335431           425.449   \n",
       "6               49.311  8.27      5.82   4.16   0.339073           431.732   \n",
       "\n",
       "     VIX  gdpGrowth  bearMarket  \n",
       "2  16.26        0.6           0  \n",
       "3  28.06       -1.0           0  \n",
       "4  27.93       -0.5           0  \n",
       "5  17.42       -0.1           0  \n",
       "6  18.64        1.2           0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keepColumns = ['Date', 'GDP', 'SP500', 'T10T3', 'uRate', 'nfci', 'USDIndex',\n",
    "       'ManufacturingConfidence', 'HousePriceIndex', 'ConsumerSentiment',\n",
    "       'PeopleOutputPerHour', 'GS10', 'FEDFUNDS', 'USNIM', 'govtToGDP',\n",
    "       'CorporateProfits', 'VIX', 'gdpGrowth', 'bearMarket'] \n",
    "newData = finalData[keepColumns]\n",
    "newData.head()\n",
    "# finalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>T10T3</th>\n",
       "      <th>uRate</th>\n",
       "      <th>nfci</th>\n",
       "      <th>USDIndex</th>\n",
       "      <th>ManufacturingConfidence</th>\n",
       "      <th>HousePriceIndex</th>\n",
       "      <th>ConsumerSentiment</th>\n",
       "      <th>PeopleOutputPerHour</th>\n",
       "      <th>GS10</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>USNIM</th>\n",
       "      <th>govtToGDP</th>\n",
       "      <th>CorporateProfits</th>\n",
       "      <th>VIX</th>\n",
       "      <th>gdpGrowth</th>\n",
       "      <th>bearMarket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/1/1990</td>\n",
       "      <td>6015.12</td>\n",
       "      <td>359.54</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>91.5346</td>\n",
       "      <td>98.75</td>\n",
       "      <td>165.84</td>\n",
       "      <td>88.2</td>\n",
       "      <td>48.200</td>\n",
       "      <td>8.47</td>\n",
       "      <td>8.15</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.326782</td>\n",
       "      <td>413.339</td>\n",
       "      <td>16.26</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1990</td>\n",
       "      <td>6004.73</td>\n",
       "      <td>314.94</td>\n",
       "      <td>1.34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>86.2694</td>\n",
       "      <td>97.85</td>\n",
       "      <td>165.20</td>\n",
       "      <td>63.9</td>\n",
       "      <td>48.054</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.11</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.334054</td>\n",
       "      <td>413.234</td>\n",
       "      <td>28.06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/1991</td>\n",
       "      <td>6035.18</td>\n",
       "      <td>326.45</td>\n",
       "      <td>1.31</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>84.878</td>\n",
       "      <td>97.13</td>\n",
       "      <td>166.57</td>\n",
       "      <td>66.8</td>\n",
       "      <td>47.927</td>\n",
       "      <td>8.09</td>\n",
       "      <td>6.91</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.327388</td>\n",
       "      <td>423.450</td>\n",
       "      <td>27.93</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/1/1991</td>\n",
       "      <td>6126.86</td>\n",
       "      <td>371.30</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>90.2577</td>\n",
       "      <td>97.82</td>\n",
       "      <td>167.70</td>\n",
       "      <td>81.8</td>\n",
       "      <td>48.449</td>\n",
       "      <td>8.04</td>\n",
       "      <td>5.91</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.335431</td>\n",
       "      <td>425.449</td>\n",
       "      <td>17.42</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/1/1991</td>\n",
       "      <td>6205.94</td>\n",
       "      <td>377.92</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>92.8816</td>\n",
       "      <td>99.58</td>\n",
       "      <td>167.99</td>\n",
       "      <td>82.9</td>\n",
       "      <td>49.311</td>\n",
       "      <td>8.27</td>\n",
       "      <td>5.82</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.339073</td>\n",
       "      <td>431.732</td>\n",
       "      <td>18.64</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      GDP   SP500  T10T3  uRate  nfci USDIndex  \\\n",
       "2   7/1/1990  6015.12  359.54   0.43    5.5 -0.23  91.5346   \n",
       "3  10/1/1990  6004.73  314.94   1.34    5.9  0.25  86.2694   \n",
       "4   1/1/1991  6035.18  326.45   1.31    6.4  0.37   84.878   \n",
       "5   4/1/1991  6126.86  371.30   2.13    6.7 -0.20  90.2577   \n",
       "6   7/1/1991  6205.94  377.92   2.50    6.8 -0.36  92.8816   \n",
       "\n",
       "   ManufacturingConfidence  HousePriceIndex ConsumerSentiment  \\\n",
       "2                    98.75           165.84              88.2   \n",
       "3                    97.85           165.20              63.9   \n",
       "4                    97.13           166.57              66.8   \n",
       "5                    97.82           167.70              81.8   \n",
       "6                    99.58           167.99              82.9   \n",
       "\n",
       "   PeopleOutputPerHour  GS10  FEDFUNDS  USNIM  govtToGDP  CorporateProfits  \\\n",
       "2               48.200  8.47      8.15   4.00   0.326782           413.339   \n",
       "3               48.054  8.72      8.11   4.03   0.334054           413.234   \n",
       "4               47.927  8.09      6.91   4.08   0.327388           423.450   \n",
       "5               48.449  8.04      5.91   4.11   0.335431           425.449   \n",
       "6               49.311  8.27      5.82   4.16   0.339073           431.732   \n",
       "\n",
       "     VIX  gdpGrowth  bearMarket  \n",
       "2  16.26        0.6         NaN  \n",
       "3  28.06       -1.0         0.0  \n",
       "4  27.93       -0.5         0.0  \n",
       "5  17.42       -0.1         0.0  \n",
       "6  18.64        1.2         0.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData.bearMarket = newData.bearMarket.shift(1)\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>T10T3</th>\n",
       "      <th>uRate</th>\n",
       "      <th>nfci</th>\n",
       "      <th>USDIndex</th>\n",
       "      <th>ManufacturingConfidence</th>\n",
       "      <th>HousePriceIndex</th>\n",
       "      <th>ConsumerSentiment</th>\n",
       "      <th>PeopleOutputPerHour</th>\n",
       "      <th>GS10</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>USNIM</th>\n",
       "      <th>govtToGDP</th>\n",
       "      <th>CorporateProfits</th>\n",
       "      <th>VIX</th>\n",
       "      <th>gdpGrowth</th>\n",
       "      <th>bearMarket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1990</td>\n",
       "      <td>6004.73</td>\n",
       "      <td>314.94</td>\n",
       "      <td>1.34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>86.2694</td>\n",
       "      <td>97.85</td>\n",
       "      <td>165.20</td>\n",
       "      <td>63.9</td>\n",
       "      <td>48.054</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.11</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.334054</td>\n",
       "      <td>413.234</td>\n",
       "      <td>28.06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/1991</td>\n",
       "      <td>6035.18</td>\n",
       "      <td>326.45</td>\n",
       "      <td>1.31</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>84.878</td>\n",
       "      <td>97.13</td>\n",
       "      <td>166.57</td>\n",
       "      <td>66.8</td>\n",
       "      <td>47.927</td>\n",
       "      <td>8.09</td>\n",
       "      <td>6.91</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.327388</td>\n",
       "      <td>423.450</td>\n",
       "      <td>27.93</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/1/1991</td>\n",
       "      <td>6126.86</td>\n",
       "      <td>371.30</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>90.2577</td>\n",
       "      <td>97.82</td>\n",
       "      <td>167.70</td>\n",
       "      <td>81.8</td>\n",
       "      <td>48.449</td>\n",
       "      <td>8.04</td>\n",
       "      <td>5.91</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.335431</td>\n",
       "      <td>425.449</td>\n",
       "      <td>17.42</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/1/1991</td>\n",
       "      <td>6205.94</td>\n",
       "      <td>377.92</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>92.8816</td>\n",
       "      <td>99.58</td>\n",
       "      <td>167.99</td>\n",
       "      <td>82.9</td>\n",
       "      <td>49.311</td>\n",
       "      <td>8.27</td>\n",
       "      <td>5.82</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.339073</td>\n",
       "      <td>431.732</td>\n",
       "      <td>18.64</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/1/1991</td>\n",
       "      <td>6264.54</td>\n",
       "      <td>389.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>88.2307</td>\n",
       "      <td>99.78</td>\n",
       "      <td>170.35</td>\n",
       "      <td>78.3</td>\n",
       "      <td>49.625</td>\n",
       "      <td>7.53</td>\n",
       "      <td>5.21</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.343762</td>\n",
       "      <td>436.638</td>\n",
       "      <td>14.81</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      GDP   SP500  T10T3  uRate  nfci USDIndex  \\\n",
       "3  10/1/1990  6004.73  314.94   1.34    5.9  0.25  86.2694   \n",
       "4   1/1/1991  6035.18  326.45   1.31    6.4  0.37   84.878   \n",
       "5   4/1/1991  6126.86  371.30   2.13    6.7 -0.20  90.2577   \n",
       "6   7/1/1991  6205.94  377.92   2.50    6.8 -0.36  92.8816   \n",
       "7  10/1/1991  6264.54  389.20   2.20    7.0 -0.49  88.2307   \n",
       "\n",
       "   ManufacturingConfidence  HousePriceIndex ConsumerSentiment  \\\n",
       "3                    97.85           165.20              63.9   \n",
       "4                    97.13           166.57              66.8   \n",
       "5                    97.82           167.70              81.8   \n",
       "6                    99.58           167.99              82.9   \n",
       "7                    99.78           170.35              78.3   \n",
       "\n",
       "   PeopleOutputPerHour  GS10  FEDFUNDS  USNIM  govtToGDP  CorporateProfits  \\\n",
       "3               48.054  8.72      8.11   4.03   0.334054           413.234   \n",
       "4               47.927  8.09      6.91   4.08   0.327388           423.450   \n",
       "5               48.449  8.04      5.91   4.11   0.335431           425.449   \n",
       "6               49.311  8.27      5.82   4.16   0.339073           431.732   \n",
       "7               49.625  7.53      5.21   4.20   0.343762           436.638   \n",
       "\n",
       "     VIX  gdpGrowth  bearMarket  \n",
       "3  28.06       -1.0         0.0  \n",
       "4  27.93       -0.5         0.0  \n",
       "5  17.42       -0.1         0.0  \n",
       "6  18.64        1.2         0.0  \n",
       "7  14.81        2.9         0.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData = newData.iloc[1:]\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag Data by 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, the data was lagged to allow for the values to have potentaial predictive ability a quarter ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adjusted data to lag it\n",
    "laggedData = pd.read_csv('newData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnColumns = ['T10T3', 'uRate', 'nfci', 'USDIndex', 'ManufacturingConfidence', 'bearMarket'] \n",
    "\n",
    "nnData = laggedData[nnColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  0]\n",
      " [ 4  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        46\n",
      "         1.0       1.00      0.64      0.78        11\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        57\n",
      "   macro avg       0.96      0.82      0.87        57\n",
      "weighted avg       0.94      0.93      0.92        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(nnData.drop('bearMarket', axis=1), nnData['bearMarket'], test_size = 0.5)\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "mlp = MLPClassifier(max_iter=150)          \n",
    "parameter_space = {'hidden_layer_sizes': [(150,150,150), (200,200,200), (250,250,250)], 'activation': ['tanh', 'relu'],\n",
    "'solver': ['sgd', 'adam'], 'alpha': [0.00025, 0.05],'learning_rate': ['constant','adaptive'],}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "predictions = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multi-layer perceptron algorithm like the one used above is made up of many individual nuerons, which are simple \n",
    "# computational units that have weighted input signals and produce an output signal using an activation function. These \n",
    "# activation functions can have a threshold, especially with a binary classifier, that decides whether zero or one is output.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A logistic regression works by classifying data based on the predict the likelihood occurrence of an event given \n",
    "# the relationship between independent and dependent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitColumns = ['GDP', 'SP500', 'T10T3', 'uRate', 'nfci', 'USDIndex',\n",
    "       'ManufacturingConfidence', 'HousePriceIndex', 'ConsumerSentiment',\n",
    "       'PeopleOutputPerHour', 'GS10', 'FEDFUNDS', 'USNIM', 'govtToGDP',\n",
    "       'CorporateProfits', 'VIX', 'gdpGrowth', 'bearMarket'] \n",
    "\n",
    "finalData = laggedData[logitColumns]\n",
    "\n",
    "X = finalData.loc[:, finalData.columns != 'bearMarket']\n",
    "y = finalData.loc[:, finalData.columns == 'bearMarket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "probac=logreg.predict_proba(X_test)\n",
    "# print(probac)\n",
    "probability = probac[:,0]\n",
    "prob_df = pd.DataFrame(probability)\n",
    "# print(prob_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  0]\n",
      " [ 0  3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        31\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        34\n",
      "   macro avg       1.00      1.00      1.00        34\n",
      "weighted avg       1.00      1.00      1.00        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between probit model and logistic regression\n",
    "\n",
    "# Basically both are linear models that have now been made nonlinear. For categorical variables\n",
    "\n",
    "# The logit model uses something called the cumulative distribution function of the logistic distribution. \n",
    "# The probit model uses something called the cumulative distribution function of the standard normal distribution \n",
    "# to define f (*). Both functions will take any number and rescale it to fall between 0 and 1. Hence, whatever  + x \n",
    "# equals, it can be transformed by the function to yield a predicted probability. Any function that would return a value\n",
    "# between zero and one would do the trick, but there is a deeper theoretical model underpinning logit and probit that \n",
    "# requires the function to be based on a probability distribution. The logistic and standard normal cdfs turn out to be \n",
    "# convenient mathematically and are programmed into just about any general purpose statistical package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A random forest mode is made of decision trees that split the data in the most efficient way into the different potential outcomes. is the building block of a random forest and is an intuitive model. We can think of a decision tree as a series of yes/no questions asked about our data eventually leading to a predicted class (or continuous value in the case of regression). This is an interpretable model because it makes classifications much like we do: we ask a sequence of queries about the available data we have until we arrive at a decision (in an ideal world)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDIndex                  0.19\n",
      "nfci                      0.13\n",
      "VIX                       0.12\n",
      "gdpGrowth                 0.09\n",
      "ManufacturingConfidence   0.07\n",
      "PeopleOutputPerHour       0.05\n",
      "CorporateProfits          0.05\n",
      "GDP                       0.05\n",
      "HousePriceIndex           0.04\n",
      "ConsumerSentiment         0.04\n",
      "T10T3                     0.03\n",
      "govtToGDP                 0.03\n",
      "SP500                     0.03\n",
      "FEDFUNDS                  0.02\n",
      "USNIM                     0.02\n",
      "GS10                      0.01\n",
      "uRate                     0.01\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=X_train.columns).sort_values(ascending=False)\n",
    "print(feature_imp)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within the random forest model, the most important features are the USDIndex, the net financial conditions index, and the VIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other. In this case, it would be the values on the two highest correlated features to bear markets. Given this, we can plot these two features on a graph, and classify whether we are in a bull market or a bear market. The \"NN\" within KNN stands for nearest neighbors, so we decide whether a new data point added to the graph is classified as a bear market or bull market based on the points around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManufacturingConfidence   -0.503642\n",
       "uRate                     -0.029143\n",
       "T10T3                      0.087757\n",
       "USDIndex                   0.368988\n",
       "nfci                       0.550893\n",
       "bearMarket                 1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCorrelations = nnData.corr().unstack().sort_values()\n",
    "dataCorrelations['bearMarket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the nfci and USDIndex since they are the highest correlated varibles to bear markets.    \n",
    "getData = ['nfci', 'USDIndex', 'bearMarket']\n",
    "\n",
    "KNNdata = nnData[getData] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def recallCalc(matrix):\n",
    "    tp = matrix[1][1] \n",
    "    fn = matrix[0][1] \n",
    "    return(np.round(tp/(tp+fn), 5))\n",
    "\n",
    "def precisionCalc(matrix): \n",
    "    tp = matrix[1][1] \n",
    "    fp = matrix[0][0] \n",
    "    return(np.round(tp/(tp+fp), 5))\n",
    "\n",
    "def fScore(precision, recall):\n",
    "    return(np.round(2 * (precision * recall) / (precision + recall), 5))\n",
    "\n",
    "def falsePositiveRate_(matrix):\n",
    "    fp = matrix[0][1] \n",
    "    tn = matrix[0][0] \n",
    "    return(np.round(fp/(fp+tn), 5))\n",
    "\n",
    "def truePositiveRate_(matrix):\n",
    "    tp = matrix[1][1] \n",
    "    fn = matrix[1][0] \n",
    "    return(np.round(tp/(tp+fn), 5))\n",
    "\n",
    "def accuracy(actual, pred):\n",
    "    return(np.round(  (pred == actual).sum()/len(actual)  , 5))\n",
    "\n",
    "def thresholdPredData(threshold, pred):\n",
    "    predMal = pred\n",
    "    for i in range(len(predMal)):\n",
    "        if((threshold == 1.0) & (predMal[i].astype(float) == 1.0)):\n",
    "            predMal[i] = 0.0\n",
    "        elif((threshold == 0.0) & (predMal[i].astype(float) == 0.0)):\n",
    "            predMal[i] = 1.0\n",
    "        elif(predMal[i] > threshold):\n",
    "            predMal[i] = 1\n",
    "        else:\n",
    "            predMal[i] = 0\n",
    "    return(predMal.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics(fitModel, xv_test, yv_test):\n",
    "    predMal = fitModel.predict_proba(xv_test)[:, 1]\n",
    "    actual = yv_test\n",
    "    w, h = 5, 11;\n",
    "    additionalData = [[0 for x in range(w)] for y in range(h)] \n",
    "    thresholds = np.round(np.linspace(0, 1, 11),6)\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "    for i in thresholds:\n",
    "        predMal = fitModel.predict_proba(xv_test)[:, 1]\n",
    "        pred = thresholdPredData(i, predMal)\n",
    "        c_matrix = confusion_matrix(actual, pred)\n",
    "        tpr.append(truePositiveRate_(c_matrix))\n",
    "        fpr.append(falsePositiveRate_(c_matrix))\n",
    "        additionalData[int(i * 10)][0] = i\n",
    "        additionalData[int(i * 10)][1] = precisionCalc(c_matrix)\n",
    "        additionalData[int(i * 10)][2] = recallCalc(c_matrix)\n",
    "        additionalData[int(i * 10)][3] = accuracy(actual, pred)\n",
    "        additionalData[int(i * 10)][4] = fScore(precisionCalc(c_matrix), recallCalc(c_matrix))\n",
    "        print(c_matrix)\n",
    "    additionalData = pd.DataFrame(data=additionalData, columns=['Threshold', 'Precision', 'Recall', 'Accuracy', 'fScore'])\n",
    "    print(additionalData)\n",
    "    df = pd.DataFrame({'threshold':thresholds, 'fpr':fpr, 'tpr':tpr})\n",
    "    plt.plot(df.fpr, df.tpr)\n",
    "    plt.plot([0, 90], [0, 90], '-')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.show()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def predictions(train_features, test_features, train_outcome, test_outcome): \n",
    "    w, h = 5, 1;\n",
    "    KNNresults = [[0 for x in range(w)] for y in range(h)] \n",
    "    KNNdatas = pd.DataFrame(KNNresults)\n",
    "    KNNdatas.columns = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "    for K in range(0, 5):\n",
    "        K = K+1\n",
    "        # uniform : uniform weights. All points in each neighborhood are weighted equally.\n",
    "        # distance : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "        for weights in ['uniform', 'distance']:\n",
    "            # ball_tree will use BallTree, kd_tree will use KDTree, brute will use a brute-force search.\n",
    "            for algo in ['ball_tree', 'kd_tree', 'brute']:\n",
    "            # manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n",
    "                for powerDistance in [1,2]:\n",
    "                    model = KNeighborsClassifier(n_neighbors = K, weights=weights, algorithm=algo, p=powerDistance)\n",
    "                    model.fit(train_features, train_outcome)  #fit the model\n",
    "                    pred=model.predict(test_features) #make prediction on test set\n",
    "                    accuracy = accuracy_score(test_outcome, pred)\n",
    "                    print([[K, weights, algo, powerDistance, accuracy]])\n",
    "                    thisList=[[K, weights, algo, powerDistance, accuracy]]\n",
    "                    KNNdatas = KNNdatas.append((thisList))      \n",
    "    KNNdatas.drop(KNNdatas.iloc[:, 1:5], inplace=True, axis=1)\n",
    "    KNNdatas.drop([\"a\"], axis = 1, inplace = True)\n",
    "    KNNdatas = KNNdatas.reset_index(drop=True)\n",
    "    KNNdatas = KNNdatas.drop(KNNdatas.index[0])\n",
    "    KNNdatas.columns = ['K', 'weights', 'algo', 'powerDistance', 'accuracy'] \n",
    "    print(KNNdatas)\n",
    "    #print(KNNdatas['accuracy'].max())\n",
    "    #print(KNNdatas['accuracy'].argmax())\n",
    "    bestData = KNNdatas.iloc[KNNdatas['accuracy'].argmax() - 1]\n",
    "    #print(bestData)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    model = KNeighborsClassifier(n_neighbors = int(bestData.K), weights=bestData.weights, algorithm=bestData.algo, p=bestData.powerDistance)\n",
    "    model.fit(train_features, train_outcome)  #fit the model\n",
    "    # This is where we could do the threshold calculation\n",
    "    analytics(model.fit(train_features, train_outcome), test_features, test_outcome)\n",
    "    #gridshow(model, train_features, train_outcome, test_features, test_outcome, nGrid=100)\n",
    "    pred=model.predict(test_features) #make prediction on test set\n",
    "    #print(pred)\n",
    "    accuracy = accuracy_score(test_outcome, pred)\n",
    "    #print(accuracy)\n",
    "    confusion_matrix(test_outcome, pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'uniform', 'ball_tree', 1, 0.9473684210526315]]\n",
      "[[1, 'uniform', 'ball_tree', 2, 0.9473684210526315]]\n",
      "[[1, 'uniform', 'kd_tree', 1, 0.9473684210526315]]\n",
      "[[1, 'uniform', 'kd_tree', 2, 0.9473684210526315]]\n",
      "[[1, 'uniform', 'brute', 1, 0.9473684210526315]]\n",
      "[[1, 'uniform', 'brute', 2, 0.9473684210526315]]\n",
      "[[1, 'distance', 'ball_tree', 1, 0.9473684210526315]]\n",
      "[[1, 'distance', 'ball_tree', 2, 0.9473684210526315]]\n",
      "[[1, 'distance', 'kd_tree', 1, 0.9473684210526315]]\n",
      "[[1, 'distance', 'kd_tree', 2, 0.9473684210526315]]\n",
      "[[1, 'distance', 'brute', 1, 0.9473684210526315]]\n",
      "[[1, 'distance', 'brute', 2, 0.9473684210526315]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2, 'uniform', 'ball_tree', 1, 0.8947368421052632]]\n",
      "[[2, 'uniform', 'ball_tree', 2, 0.8947368421052632]]\n",
      "[[2, 'uniform', 'kd_tree', 1, 0.8947368421052632]]\n",
      "[[2, 'uniform', 'kd_tree', 2, 0.8947368421052632]]\n",
      "[[2, 'uniform', 'brute', 1, 0.8947368421052632]]\n",
      "[[2, 'uniform', 'brute', 2, 0.8947368421052632]]\n",
      "[[2, 'distance', 'ball_tree', 1, 0.9473684210526315]]\n",
      "[[2, 'distance', 'ball_tree', 2, 0.9473684210526315]]\n",
      "[[2, 'distance', 'kd_tree', 1, 0.9473684210526315]]\n",
      "[[2, 'distance', 'kd_tree', 2, 0.9473684210526315]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2, 'distance', 'brute', 1, 0.9473684210526315]]\n",
      "[[2, 'distance', 'brute', 2, 0.9473684210526315]]\n",
      "[[3, 'uniform', 'ball_tree', 1, 0.8947368421052632]]\n",
      "[[3, 'uniform', 'ball_tree', 2, 0.8947368421052632]]\n",
      "[[3, 'uniform', 'kd_tree', 1, 0.8947368421052632]]\n",
      "[[3, 'uniform', 'kd_tree', 2, 0.8947368421052632]]\n",
      "[[3, 'uniform', 'brute', 1, 0.8947368421052632]]\n",
      "[[3, 'uniform', 'brute', 2, 0.8947368421052632]]\n",
      "[[3, 'distance', 'ball_tree', 1, 0.9210526315789473]]\n",
      "[[3, 'distance', 'ball_tree', 2, 0.9210526315789473]]\n",
      "[[3, 'distance', 'kd_tree', 1, 0.9210526315789473]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[3, 'distance', 'kd_tree', 2, 0.9210526315789473]]\n",
      "[[3, 'distance', 'brute', 1, 0.9210526315789473]]\n",
      "[[3, 'distance', 'brute', 2, 0.9210526315789473]]\n",
      "[[4, 'uniform', 'ball_tree', 1, 0.8947368421052632]]\n",
      "[[4, 'uniform', 'ball_tree', 2, 0.8947368421052632]]\n",
      "[[4, 'uniform', 'kd_tree', 1, 0.8947368421052632]]\n",
      "[[4, 'uniform', 'kd_tree', 2, 0.8947368421052632]]\n",
      "[[4, 'uniform', 'brute', 1, 0.8947368421052632]]\n",
      "[[4, 'uniform', 'brute', 2, 0.8947368421052632]]\n",
      "[[4, 'distance', 'ball_tree', 1, 0.9210526315789473]]\n",
      "[[4, 'distance', 'ball_tree', 2, 0.9210526315789473]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 'distance', 'kd_tree', 1, 0.9210526315789473]]\n",
      "[[4, 'distance', 'kd_tree', 2, 0.9210526315789473]]\n",
      "[[4, 'distance', 'brute', 1, 0.9210526315789473]]\n",
      "[[4, 'distance', 'brute', 2, 0.9210526315789473]]\n",
      "[[5, 'uniform', 'ball_tree', 1, 0.8947368421052632]]\n",
      "[[5, 'uniform', 'ball_tree', 2, 0.8947368421052632]]\n",
      "[[5, 'uniform', 'kd_tree', 1, 0.8947368421052632]]\n",
      "[[5, 'uniform', 'kd_tree', 2, 0.8947368421052632]]\n",
      "[[5, 'uniform', 'brute', 1, 0.8947368421052632]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[5, 'uniform', 'brute', 2, 0.8947368421052632]]\n",
      "[[5, 'distance', 'ball_tree', 1, 0.9210526315789473]]\n",
      "[[5, 'distance', 'ball_tree', 2, 0.9210526315789473]]\n",
      "[[5, 'distance', 'kd_tree', 1, 0.9210526315789473]]\n",
      "[[5, 'distance', 'kd_tree', 2, 0.9210526315789473]]\n",
      "[[5, 'distance', 'brute', 1, 0.9210526315789473]]\n",
      "[[5, 'distance', 'brute', 2, 0.9210526315789473]]\n",
      "      K   weights       algo  powerDistance  accuracy\n",
      "1  1.00   uniform  ball_tree           1.00      0.95\n",
      "2  1.00   uniform  ball_tree           2.00      0.95\n",
      "3  1.00   uniform    kd_tree           1.00      0.95\n",
      "4  1.00   uniform    kd_tree           2.00      0.95\n",
      "5  1.00   uniform      brute           1.00      0.95\n",
      "6  1.00   uniform      brute           2.00      0.95\n",
      "7  1.00  distance  ball_tree           1.00      0.95\n",
      "8  1.00  distance  ball_tree           2.00      0.95\n",
      "9  1.00  distance    kd_tree           1.00      0.95\n",
      "10 1.00  distance    kd_tree           2.00      0.95\n",
      "11 1.00  distance      brute           1.00      0.95\n",
      "12 1.00  distance      brute           2.00      0.95\n",
      "13 2.00   uniform  ball_tree           1.00      0.89\n",
      "14 2.00   uniform  ball_tree           2.00      0.89\n",
      "15 2.00   uniform    kd_tree           1.00      0.89\n",
      "16 2.00   uniform    kd_tree           2.00      0.89\n",
      "17 2.00   uniform      brute           1.00      0.89\n",
      "18 2.00   uniform      brute           2.00      0.89\n",
      "19 2.00  distance  ball_tree           1.00      0.95\n",
      "20 2.00  distance  ball_tree           2.00      0.95\n",
      "21 2.00  distance    kd_tree           1.00      0.95\n",
      "22 2.00  distance    kd_tree           2.00      0.95\n",
      "23 2.00  distance      brute           1.00      0.95\n",
      "24 2.00  distance      brute           2.00      0.95\n",
      "25 3.00   uniform  ball_tree           1.00      0.89\n",
      "26 3.00   uniform  ball_tree           2.00      0.89\n",
      "27 3.00   uniform    kd_tree           1.00      0.89\n",
      "28 3.00   uniform    kd_tree           2.00      0.89\n",
      "29 3.00   uniform      brute           1.00      0.89\n",
      "30 3.00   uniform      brute           2.00      0.89\n",
      "31 3.00  distance  ball_tree           1.00      0.92\n",
      "32 3.00  distance  ball_tree           2.00      0.92\n",
      "33 3.00  distance    kd_tree           1.00      0.92\n",
      "34 3.00  distance    kd_tree           2.00      0.92\n",
      "35 3.00  distance      brute           1.00      0.92\n",
      "36 3.00  distance      brute           2.00      0.92\n",
      "37 4.00   uniform  ball_tree           1.00      0.89\n",
      "38 4.00   uniform  ball_tree           2.00      0.89\n",
      "39 4.00   uniform    kd_tree           1.00      0.89\n",
      "40 4.00   uniform    kd_tree           2.00      0.89\n",
      "41 4.00   uniform      brute           1.00      0.89\n",
      "42 4.00   uniform      brute           2.00      0.89\n",
      "43 4.00  distance  ball_tree           1.00      0.92\n",
      "44 4.00  distance  ball_tree           2.00      0.92\n",
      "45 4.00  distance    kd_tree           1.00      0.92\n",
      "46 4.00  distance    kd_tree           2.00      0.92\n",
      "47 4.00  distance      brute           1.00      0.92\n",
      "48 4.00  distance      brute           2.00      0.92\n",
      "49 5.00   uniform  ball_tree           1.00      0.89\n",
      "50 5.00   uniform  ball_tree           2.00      0.89\n",
      "51 5.00   uniform    kd_tree           1.00      0.89\n",
      "52 5.00   uniform    kd_tree           2.00      0.89\n",
      "53 5.00   uniform      brute           1.00      0.89\n",
      "54 5.00   uniform      brute           2.00      0.89\n",
      "55 5.00  distance  ball_tree           1.00      0.92\n",
      "56 5.00  distance  ball_tree           2.00      0.92\n",
      "57 5.00  distance    kd_tree           1.00      0.92\n",
      "58 5.00  distance    kd_tree           2.00      0.92\n",
      "59 5.00  distance      brute           1.00      0.92\n",
      "60 5.00  distance      brute           2.00      0.92\n",
      "[[ 0 32]\n",
      " [ 0  6]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 2  4]]\n",
      "[[32  0]\n",
      " [ 6  0]]\n",
      "    Threshold  Precision  Recall  Accuracy  fScore\n",
      "0        0.00       1.00    0.16      0.16    0.27\n",
      "1        0.10       0.11    1.00      0.95    0.20\n",
      "2        0.20       0.11    1.00      0.95    0.20\n",
      "3        0.30       0.11    1.00      0.95    0.20\n",
      "4        0.40       0.11    1.00      0.95    0.20\n",
      "5        0.50       0.11    1.00      0.95    0.20\n",
      "6        0.60       0.11    1.00      0.95    0.20\n",
      "7        0.70       0.11    1.00      0.95    0.20\n",
      "8        0.80       0.11    1.00      0.95    0.20\n",
      "9        0.90       0.11    1.00      0.95    0.20\n",
      "10       1.00       0.00     nan      0.84     nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threshold  fpr  tpr\n",
      "0        0.00 1.00 1.00\n",
      "1        0.10 0.00 0.67\n",
      "2        0.20 0.00 0.67\n",
      "3        0.30 0.00 0.67\n",
      "4        0.40 0.00 0.67\n",
      "5        0.50 0.00 0.67\n",
      "6        0.60 0.00 0.67\n",
      "7        0.70 0.00 0.67\n",
      "8        0.80 0.00 0.67\n",
      "9        0.90 0.00 0.67\n",
      "10       1.00 0.00 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "train_features, test_features, train_outcome, test_outcome = train_test_split(\n",
    "KNNdata.drop(['bearMarket'], axis = 1), \n",
    "    KNNdata['bearMarket'], \n",
    "    test_size = .33, \n",
    "    random_state = 7)\n",
    "predictionsDataframe = pd.DataFrame(test_outcome)\n",
    "predictionsDataframe['predictions'] = predictions(train_features, test_features, train_outcome, test_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this case on average, it seems that 1 neighbor was the most accurate classifier at ~95% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
